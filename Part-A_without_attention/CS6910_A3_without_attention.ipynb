{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8151136,"sourceType":"datasetVersion","datasetId":4820823}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing all the necessary libraries**","metadata":{}},{"cell_type":"code","source":"# # Create Adam optimizer with default parameters\n# optimizer = torch.optim.Adam(model.parameters())\n\n# # Modify learning rate\n# new_learning_rate = 0.001  # Set your desired learning rate\n# for param_group in optimizer.param_groups:\n#     param_group['lr'] = new_learning_rate\n\n# # Modify other parameters\n# # For example, to change weight decay\n# new_weight_decay = 0.01  # Set your desired weight decay value\n# for param_group in optimizer.param_groups:\n#     param_group['weight_decay'] = new_weight_decay\n","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:15.598449Z","iopub.execute_input":"2024-05-14T14:31:15.598761Z","iopub.status.idle":"2024-05-14T14:31:19.806634Z","shell.execute_reply.started":"2024-05-14T14:31:15.598737Z","shell.execute_reply":"2024-05-14T14:31:19.805631Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## **Encoder class**","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, rnn_cell='lstm', dropout=0.5, bidirectional=True):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bidirectional = bidirectional\n        \n        rnn_hidden_size = hidden_size // 2 if bidirectional else hidden_size\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)\n        elif rnn_cell.lower() == 'gru':\n            self.rnn = nn.GRU(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)\n        else:\n            self.rnn = nn.RNN(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        embedded = self.dropout(embedded)\n        outputs, hidden = self.rnn(embedded)\n\n        if self.bidirectional:\n            if isinstance(hidden, tuple):\n                h_n, c_n = hidden\n#                 print('enc h bef dir',h_n.shape)\n#                 print('enc c bef dir',c_n.shape)\n                h_n = torch.cat((h_n[0::2], h_n[1::2]), dim=2)\n                c_n = torch.cat((c_n[0::2], c_n[1::2]), dim=2)\n#                 print('enc h af dir',h_n.shape)\n#                 print('enc c af dir',c_n.shape)\n                hidden = (h_n, c_n)\n            else:\n#                 print('enc hidd bef dir',hidden.shape)\n                hidden = torch.cat((hidden[0::2], hidden[1::2]), dim=2)\n#                 print('after dir enc:',hidden.shape)\n\n        return hidden","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:29.110296Z","iopub.execute_input":"2024-05-14T14:31:29.111028Z","iopub.status.idle":"2024-05-14T14:31:29.123786Z","shell.execute_reply.started":"2024-05-14T14:31:29.110992Z","shell.execute_reply":"2024-05-14T14:31:29.122665Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Decoder class**","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers, encoder_num_layers, rnn_cell='lstm', dropout=0.5, bidirectional=True):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.output_size = output_size\n        self.hidden_size = hidden_size * encoder_num_layers if bidirectional else hidden_size\n        self.num_layers = num_layers\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))\n        elif rnn_cell.lower() == 'gru':\n            self.rnn = nn.GRU(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))\n        else:\n            self.rnn = nn.RNN(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))\n        \n        self.fc = nn.Linear(self.hidden_size, output_size)\n\n    def forward(self, x, hidden):\n        x = x.unsqueeze(1)\n        embedded = self.dropout(self.embedding(x))\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.fc(self.dropout(output.squeeze(1)))\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:30.085132Z","iopub.execute_input":"2024-05-14T14:31:30.085770Z","iopub.status.idle":"2024-05-14T14:31:30.095609Z","shell.execute_reply.started":"2024-05-14T14:31:30.085741Z","shell.execute_reply":"2024-05-14T14:31:30.094647Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Sequence to Sequence model for the above encoder and decoder**","metadata":{}},{"cell_type":"code","source":"class Seq_to_Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq_to_Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teaching_force_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        target_vocab_size = self.decoder.output_size\n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(source.device)\n        \n        encoder_hidden = self.encoder(source)\n        \n        if isinstance(encoder_hidden, tuple):\n            h_n, c_n = encoder_hidden\n#             print('enc h bef dir',h_n.shape)\n#             print('enc c bef dir',c_n.shape)\n            if self.encoder.bidirectional:\n#                 h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)\n######\n#                 print('enc h bef dir',h_n.shape)\n#                 print('enc c bef dir',c_n.shape)\n                h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)\n                c_n = torch.cat([c_n[i:i+1] for i in range(0, c_n.shape[0], 2)] + [c_n[i:i+1] for i in range(1, c_n.shape[0], 2)], dim=2)\n#                 print('enc h af dir',h_n.shape)\n#                 print('enc c af dir',c_n.shape)\n            \n            if h_n.size(0) < self.decoder.num_layers:\n#                 zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.decoder.hidden_size, device=h_n.device)\n#                 zero_c = torch.zeros(self.decoder.num_layers - c_n.size(0), batch_size, self.decoder.hidden_size, device=c_n.device)\n                zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=h_n.device)\n                zero_c = torch.zeros(self.decoder.num_layers - c_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=c_n.device)\n#                 print(zero_h.shape)\n#                 print(zero_c.shape)\n                h_n = torch.cat([h_n, zero_h], dim=0)\n                c_n = torch.cat([c_n, zero_c], dim=0)\n#                 print(h_n.shape)\n#                 print(c_n.shape)\n\n            encoder_hidden = (h_n[:self.decoder.num_layers], c_n[:self.decoder.num_layers])\n#             print('encoder_hidden h_n shape',encoder_hidden[0].shape)\n        else:\n            h_n = encoder_hidden\n#             print(h_n.shape)\n            if self.encoder.bidirectional:\n                h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)\n####                print('encoder_hidden shape is: ',h_n.shape)\n#             encoder_hidden = h_n[:self.decoder.num_layers]\n#             print(encoder_hidden.shape)\n#             if self.encoder.bidirectional:\n#                 print('encoder_hidden shape is: ',encoder_hidden.shape)\n# #                 encoder_hidden = torch.cat((encoder_hidden[0:encoder_hidden.size(0):2], encoder_hidden[1:encoder_hidden.size(0):2]), dim=2)\n# #                 encoder_hidden = encoder_hidden.view(self.encoder.num_layers, 2, batch_size, self.encoder.hidden_size)\n#                 print(encoder_hidden.shape) \n# #                 encoder_hidden = torch.cat((encoder_hidden[:, 0, :, :], encoder_hidden[:, 1, :, :]), dim=2)\n                \n# enc hidd bef dir torch.Size([4, 64, 256])\n# after dir enc: torch.Size([2, 64, 512])\n# torch.Size([2, 64, 512])\n# torch.Size([1, 64, 1024])\n# torch.Size([1, 64, 1024])\n            if h_n.size(0) < self.decoder.num_layers:\n                zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=encoder_hidden.device)\n#                 print('zero',zero_h.shape)\n                h_n = torch.cat([h_n, zero_h], dim=0)\n            encoder_hidden = h_n[:self.decoder.num_layers]\n#             print('encoder_hidden shape is: ',encoder_hidden.shape)\n        \n        decoder_input = target[:, 0]\n#         print('decoder_input',decoder_input.shape)\n                    \n        for t in range(1, target_len):\n            decoder_output, encoder_hidden = self.decoder(decoder_input, encoder_hidden)\n#             print('hghg')\n            outputs[:, t] = decoder_output\n            teacher_force = torch.rand(1) < teaching_force_ratio\n            top1 = decoder_output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n\n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:44.549605Z","iopub.execute_input":"2024-05-14T14:31:44.550269Z","iopub.status.idle":"2024-05-14T14:31:44.569318Z","shell.execute_reply.started":"2024-05-14T14:31:44.550234Z","shell.execute_reply":"2024-05-14T14:31:44.568373Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, rnn_cell='lstm', dropout=0.5, bidirectional=True):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bidirectional = bidirectional\n        \n        rnn_hidden_size = hidden_size // 2 if bidirectional else hidden_size\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)\n        elif rnn_cell.lower() == 'gru':\n            self.rnn = nn.GRU(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)\n        else:\n            self.rnn = nn.RNN(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        embedded = self.dropout(embedded)\n        outputs, hidden = self.rnn(embedded)\n\n        if self.bidirectional:\n            if isinstance(hidden, tuple):\n                h_n, c_n = hidden\n                h_n = torch.cat((h_n[0::2], h_n[1::2]), dim=2)\n                c_n = torch.cat((c_n[0::2], c_n[1::2]), dim=2)\n                hidden = (h_n, c_n)\n            else:\n                hidden = torch.cat((hidden[0::2], hidden[1::2]), dim=2)\n\n        return hidden\n\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers, encoder_num_layers, rnn_cell='lstm', dropout=0.5, bidirectional=True):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.output_size = output_size\n        self.hidden_size = hidden_size * encoder_num_layers if bidirectional else hidden_size\n        self.num_layers = num_layers\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))\n        elif rnn_cell.lower() == 'gru':\n            self.rnn = nn.GRU(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))\n        else:\n            self.rnn = nn.RNN(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))\n        \n        self.fc = nn.Linear(self.hidden_size, output_size)\n\n    def forward(self, x, hidden):\n        x = x.unsqueeze(1)\n        embedded = self.dropout(self.embedding(x))\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.fc(self.dropout(output.squeeze(1)))\n        return output, hidden\n    \n    \n\nclass Seq_to_Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq_to_Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teaching_force_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        target_vocab_size = self.decoder.output_size\n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(source.device)\n        \n        encoder_hidden = self.encoder(source)\n        \n        if isinstance(encoder_hidden, tuple):\n            h_n, c_n = encoder_hidden\n            if self.encoder.bidirectional:\n                h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)\n                c_n = torch.cat([c_n[i:i+1] for i in range(0, c_n.shape[0], 2)] + [c_n[i:i+1] for i in range(1, c_n.shape[0], 2)], dim=2)\n            \n            if h_n.size(0) < self.decoder.num_layers:\n                zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=h_n.device)\n                zero_c = torch.zeros(self.decoder.num_layers - c_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=c_n.device)\n                h_n = torch.cat([h_n, zero_h], dim=0)\n                c_n = torch.cat([c_n, zero_c], dim=0)\n\n            encoder_hidden = (h_n[:self.decoder.num_layers], c_n[:self.decoder.num_layers])\n        else:\n            h_n = encoder_hidden\n            if self.encoder.bidirectional:\n                h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)\n            \n            if h_n.size(0) < self.decoder.num_layers:\n                zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=encoder_hidden.device)\n                h_n = torch.cat([h_n, zero_h], dim=0)\n            encoder_hidden = h_n[:self.decoder.num_layers]\n        \n        decoder_input = target[:, 0]\n                    \n        for t in range(1, target_len):\n            decoder_output, encoder_hidden = self.decoder(decoder_input, encoder_hidden)\n            outputs[:, t] = decoder_output\n            teacher_force = torch.rand(1) < teaching_force_ratio\n            top1 = decoder_output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n\n        return outputs\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########################\n# def create_vocab(text):\n#     vocab = set(char for word in text for char in word)\n#     vocab.add('<pad>')\n#     vocab.add('<sos>')\n#     vocab.add('<eos>')\n#     return vocab\n\n# def load_data(path):\n#     df = pd.read_csv(path, header=None, names=['latin', 'bangla'])\n#     return df['latin'], df['bangla']\n\n# latin_train, bangla_train = load_data('/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_train.csv')\n# latin_vocab = create_vocab(latin_train)\n# bangla_vocab = create_vocab(bangla_train)\n# latin_token_to_index = {token: index for index, token in enumerate(sorted(latin_vocab))}\n# bangla_token_to_index = {token: index for index, token in enumerate(sorted(bangla_vocab))}\n\n# print(latin_token_to_index)\n# print()\n# print(bangla_token_to_index)\n\n# class AksharantarDataset(Dataset):\n#     def __init__(self, latin_words, bangla_words, latin_token_to_index, bangla_token_to_index):\n#         self.latin_words = latin_words\n#         self.bangla_words = bangla_words\n#         self.latin_token_to_index = latin_token_to_index\n#         self.bangla_token_to_index = bangla_token_to_index\n\n#     def __len__(self):\n#         return len(self.latin_words)\n\n#     def __getitem__(self, index):\n#         latin_word = self.latin_words.iloc[index]\n#         bangla_word = self.bangla_words.iloc[index]\n#         latin_indices = [latin_token_to_index[char] for char in latin_word]\n#         bangla_indices = [bangla_token_to_index['<sos>']] + [bangla_token_to_index[char] for char in bangla_word] + [bangla_token_to_index['<eos>']]\n#         return torch.tensor(latin_indices, dtype=torch.long), torch.tensor(bangla_indices, dtype=torch.long)\n\n# def packet_fn(batch):\n#     latin, bangla = zip(*batch)\n#     latin_padded = pad_sequence(latin, batch_first=True, padding_value=latin_token_to_index['<pad>'])\n#     bangla_padded = pad_sequence(bangla, batch_first=True, padding_value=bangla_token_to_index['<pad>'])\n#     return latin_padded, bangla_padded\n\n# train_dataset = AksharantarDataset(latin_train, bangla_train, latin_token_to_index, bangla_token_to_index)\n# train_loader = DataLoader(train_dataset, batch_size = 64, collate_fn=packet_fn, shuffle=True)\n\n# def word_accuracy(outputs, targets, ignore_index):\n#     correct = 0\n#     total = 0\n#     for out, tar in zip(outputs, targets):\n#         out = out[out != ignore_index]\n#         tar = tar[tar != ignore_index]\n#         ignore_index_eos = 0\n#         out = out[out != ignore_index_eos]\n#         tar = tar[tar != ignore_index_eos]\n#         if torch.equal(out, tar):\n#             correct += 1\n#         total += 1\n#     return correct / total if total > 0 else 0\n\n\n# def train(model, iterator, optimizer, criterion, clip, device, ignore_index):\n#     model.train()\n#     epoch_loss = 0\n#     epoch_acc = 0\n    \n#     for source, target in iterator:\n#         source = source.to(device)\n#         target = target.to(device)\n        \n#         optimizer.zero_grad()\n#         output = model(source, target)\n        \n#         output_dim = output.shape[-1]\n#         output = output[:, 1:, :]\n#         target = target[:, 1:]\n        \n#         output_flat = output.reshape(-1, output_dim)\n#         target_flat = target.reshape(-1)\n        \n#         loss = criterion(output_flat, target_flat)\n#         acc = word_accuracy(output.argmax(dim=2), target, ignore_index)\n        \n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n#         optimizer.step()\n        \n#         epoch_loss += loss.item()\n#         epoch_acc += acc\n    \n#     return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n# def evaluate(model, iterator, criterion, device, ignore_index):\n#     model.eval()\n#     epoch_loss = 0\n#     epoch_acc = 0\n    \n#     with torch.no_grad():\n#         for source, target in iterator:\n#             source = source.to(device)\n#             target = target.to(device)\n            \n#             output = model(source, target, 0)\n#             output_dim = output.shape[-1]\n#             output = output[:, 1:, :]\n#             target = target[:, 1:]\n            \n#             output_flat = output.reshape(-1, output_dim)\n#             target_flat = target.reshape(-1)\n#             loss = criterion(output_flat, target_flat)\n#             acc = word_accuracy(output.argmax(dim=2), target, ignore_index)\n            \n#             epoch_loss += loss.item()\n#             epoch_acc += acc\n            \n#     return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n# latin_valid, bangla_valid = load_data('/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_valid.csv')\n# valid_dataset = AksharantarDataset(latin_valid, bangla_valid, latin_token_to_index, bangla_token_to_index)\n# valid_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=packet_fn, shuffle=True)\n\n\n\n# NUM_EPOCHS = 1\n# CLIP = 1\n# optimizer = torch.optim.Adam(model.parameters())\n# ignore_index = bangla_token_to_index['<pad>']\n# criterion = nn.CrossEntropyLoss(ignore_index=ignore_index).to(device)\n\n# for epoch in range(NUM_EPOCHS):\n#     train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n#     val_loss, val_accuracy = evaluate(model, valid_loader, criterion, device, ignore_index)\n    \n#     print(f'Epoch: {epoch+1}')\n#     print(f'\\tTrain_Loss: {train_loss:.3f}, Train_Accuracy: {train_accuracy*100:.2f}%')\n#     print(f'\\tVal_Loss: {val_loss:.3f},  Val_Accuracy: {val_accuracy*100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:43:23.137408Z","iopub.execute_input":"2024-05-14T14:43:23.137798Z","iopub.status.idle":"2024-05-14T14:43:23.147773Z","shell.execute_reply.started":"2024-05-14T14:43:23.137766Z","shell.execute_reply":"2024-05-14T14:43:23.146480Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# **Printing the model**","metadata":{}},{"cell_type":"code","source":"INPUT_DIM = 100\nOUTPUT_DIM = 100\nENC_EMB_DIM = 256\nDEC_EMB_DIM = 256\nHID_DIM = 512\nENC_LAYERS = 1\nDEC_LAYERS = 3\nENC_RNN_CELL = 'gru'\nDEC_RNN_CELL = 'gru'\n\nencoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL,dropout=0.3, bidirectional = True)\ndecoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout=0.3, bidirectional = True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nmodel = Seq_to_Seq(encoder, decoder).to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:52.098690Z","iopub.execute_input":"2024-05-14T14:31:52.099044Z","iopub.status.idle":"2024-05-14T14:31:52.482872Z","shell.execute_reply.started":"2024-05-14T14:31:52.099016Z","shell.execute_reply":"2024-05-14T14:31:52.481997Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(256, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(256, 512, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **A function to create a vocabulary set from the given text**","metadata":{}},{"cell_type":"code","source":"\n# Define a function to create a vocabulary set from a given text\ndef create_vocab(text):\n    # Create a set of unique characters found in the text\n    # Each word in the text is processed to extract its characters\n    vocab = set(char for word in text for char in word)\n    # Add a padding token to the vocabulary\n    vocab.add('<pad>')\n    # Add a start-of-sequence token to the vocabulary\n    vocab.add('<sos>')  # Start of sequence token\n    # Add an end-of-sequence token to the vocabulary\n    vocab.add('<eos>')  # End of sequence token\n    # Return the complete set of vocabulary items\n    return vocab","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:53.273149Z","iopub.execute_input":"2024-05-14T14:31:53.273518Z","iopub.status.idle":"2024-05-14T14:31:53.279110Z","shell.execute_reply.started":"2024-05-14T14:31:53.273490Z","shell.execute_reply":"2024-05-14T14:31:53.278097Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **A function to load data from a CSV file**","metadata":{}},{"cell_type":"code","source":"# Define a function to load data from a CSV file\ndef load_data(path):\n    # The file has no header and columns are named as 'latin' and 'bangla'\n    df = pd.read_csv(path, header=None, names=['latin', 'bangla'])\n#     df = df.head(10)\n    # Return the columns as two separate Series objects\n    return df['latin'], df['bangla']","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:53.800467Z","iopub.execute_input":"2024-05-14T14:31:53.800821Z","iopub.status.idle":"2024-05-14T14:31:53.805913Z","shell.execute_reply.started":"2024-05-14T14:31:53.800793Z","shell.execute_reply":"2024-05-14T14:31:53.804912Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Load Latin and bangla training data**","metadata":{}},{"cell_type":"code","source":"# Load Latin and bangla training data from specified path\nlatin_train, bangla_train = load_data('/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:56.133767Z","iopub.execute_input":"2024-05-14T14:31:56.134433Z","iopub.status.idle":"2024-05-14T14:31:56.284413Z","shell.execute_reply.started":"2024-05-14T14:31:56.134403Z","shell.execute_reply":"2024-05-14T14:31:56.283473Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **Print the loaded Latin and Bangla training data**","metadata":{}},{"cell_type":"code","source":"# Print the loaded Latin training data\nprint(latin_train)\nprint()\n# Print the loaded bangla training data\nprint(bangla_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:57.478887Z","iopub.execute_input":"2024-05-14T14:31:57.479247Z","iopub.status.idle":"2024-05-14T14:31:57.487743Z","shell.execute_reply.started":"2024-05-14T14:31:57.479220Z","shell.execute_reply":"2024-05-14T14:31:57.486723Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"0        namdharirao\n1        hindukusher\n2        farajikandi\n3           moubarak\n4             chiung\n            ...     \n51195       silmadar\n51196        jonnote\n51197      handibage\n51198         borpar\n51199     bideshikei\nName: latin, Length: 51200, dtype: object\n\n0            নামধারীরাও\n1           হিন্দুকুশের\n2           ফরাজীকান্দি\n3                মুবারক\n4                চিয়ুং\n              ...      \n51195          সিলমাদার\n51196            জন্যতে\n51197    হ্যান্ডিব্যাগে\n51198             বরপার\n51199         বিদেশীকেই\nName: bangla, Length: 51200, dtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Create two vocabularies from the Latin and Bangla training data**","metadata":{}},{"cell_type":"code","source":"# Create a vocabulary from the Latin training data\nlatin_vocab = create_vocab(latin_train)\n# Create a vocabulary from the bangla training data\nbangla_vocab = create_vocab(bangla_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:58.232761Z","iopub.execute_input":"2024-05-14T14:31:58.233110Z","iopub.status.idle":"2024-05-14T14:31:58.330382Z","shell.execute_reply.started":"2024-05-14T14:31:58.233083Z","shell.execute_reply":"2024-05-14T14:31:58.329676Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Print the created Latin and Bangla vocabularies**","metadata":{}},{"cell_type":"code","source":"# Print the created Latin vocabulary\nprint(latin_vocab)\nprint()\n# Print the created bangla vocabulary\nprint(bangla_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:31:59.166910Z","iopub.execute_input":"2024-05-14T14:31:59.167748Z","iopub.status.idle":"2024-05-14T14:31:59.172527Z","shell.execute_reply.started":"2024-05-14T14:31:59.167715Z","shell.execute_reply":"2024-05-14T14:31:59.171449Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'h', 'k', '<pad>', 'd', 'b', 'f', 'g', 's', 'r', 'c', 'x', 'q', 'y', 'j', 'm', 'l', 'v', 'e', '<sos>', 'u', 'a', 'p', '<eos>', 'o', 'n', 't', 'w', 'z', 'i'}\n\n{'ঈ', 'খ', 'শ', 'ঔ', 'আ', '<pad>', 'ধ', 'ঞ', 'ৈ', 'য', 'ঃ', 'প', 'ঢ', 'থ', 'ঋ', 'র', 'ড', 'স', 'ক', 'ট', 'ু', 'এ', 'ম', 'ব', 'ই', 'া', '্', 'ভ', 'উ', 'ৎ', 'গ', '<sos>', 'ল', 'ৌ', 'ৃ', 'ঐ', 'ন', 'চ', 'ষ', 'ি', 'দ', '়', 'ত', 'ণ', 'ঠ', 'ছ', 'ঊ', 'ূ', 'ং', '<eos>', 'হ', 'জ', 'ও', 'ঝ', 'ী', 'ে', 'ঙ', 'ঘ', 'ঁ', 'ফ', 'ো', '২', 'অ'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Map each token in the Latin and Bangla vocabularies to a unique index and then Print the dictionaries mapping (Latin tokens to indices) and (Bangla tokens to indices)**\n","metadata":{}},{"cell_type":"code","source":"# Map each token in the Latin vocabulary to a unique index\nlatin_token_to_index = {token: index for index, token in enumerate(sorted(latin_vocab))}\n# Map each token in the bangla vocabulary to a unique index\nbangla_token_to_index = {token: index for index, token in enumerate(sorted(bangla_vocab))}\n\n# Print the dictionary mapping Latin tokens to indices\nprint(latin_token_to_index)\nprint()\n\n# Print the dictionary mapping bangla tokens to indices\nprint(bangla_token_to_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:01.686676Z","iopub.execute_input":"2024-05-14T14:32:01.687031Z","iopub.status.idle":"2024-05-14T14:32:01.693209Z","shell.execute_reply.started":"2024-05-14T14:32:01.687003Z","shell.execute_reply":"2024-05-14T14:32:01.692082Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'<eos>': 0, '<pad>': 1, '<sos>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n\n{'<eos>': 0, '<pad>': 1, '<sos>': 2, 'ঁ': 3, 'ং': 4, 'ঃ': 5, 'অ': 6, 'আ': 7, 'ই': 8, 'ঈ': 9, 'উ': 10, 'ঊ': 11, 'ঋ': 12, 'এ': 13, 'ঐ': 14, 'ও': 15, 'ঔ': 16, 'ক': 17, 'খ': 18, 'গ': 19, 'ঘ': 20, 'ঙ': 21, 'চ': 22, 'ছ': 23, 'জ': 24, 'ঝ': 25, 'ঞ': 26, 'ট': 27, 'ঠ': 28, 'ড': 29, 'ঢ': 30, 'ণ': 31, 'ত': 32, 'থ': 33, 'দ': 34, 'ধ': 35, 'ন': 36, 'প': 37, 'ফ': 38, 'ব': 39, 'ভ': 40, 'ম': 41, 'য': 42, 'র': 43, 'ল': 44, 'শ': 45, 'ষ': 46, 'স': 47, 'হ': 48, '়': 49, 'া': 50, 'ি': 51, 'ী': 52, 'ু': 53, 'ূ': 54, 'ৃ': 55, 'ে': 56, 'ৈ': 57, 'ো': 58, 'ৌ': 59, '্': 60, 'ৎ': 61, '২': 62}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Defining a Dataset class for handling Latin and Bangla word pairs**","metadata":{}},{"cell_type":"code","source":"# Define a Dataset class for handling Latin and Bangla word pairs\nclass AksharantarDataset(Dataset):\n    def __init__(self, latin_words, bangla_words, latin_token_to_index, bangla_token_to_index):\n        # Store the lists of Latin and Bangla words\n        self.latin_words = latin_words\n        self.bangla_words = bangla_words\n        # Store the dictionaries that map characters to indices for both languages\n        self.latin_token_to_index = latin_token_to_index\n        self.bangla_token_to_index = bangla_token_to_index\n\n    def __len__(self):\n        # Return the number of word pairs in the dataset\n        return len(self.latin_words)\n\n    def __getitem__(self, index):\n        # Fetching the Latin and Bangla words at the specified index\n        latin_word = self.latin_words.iloc[index]\n#         print(latin_word)\n        bangla_word = self.bangla_words.iloc[index]\n#         print(bangla_word)\n        # Convert the Latin word into indices using the latin_token_to_index mapping\n        latin_indices = [latin_token_to_index[char] for char in latin_word]\n#         print(latin_indices)\n        # Convert the Bangla word into indices, adding <sos> and <eos> tokens\n        bangla_indices = [bangla_token_to_index['<sos>']] + [bangla_token_to_index[char] for char in bangla_word] + [bangla_token_to_index['<eos>']]\n#         print(bangla_indices)\n        # Return the indices as tensor objects\n        return torch.tensor(latin_indices, dtype=torch.long), torch.tensor(bangla_indices, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:06.933560Z","iopub.execute_input":"2024-05-14T14:32:06.933924Z","iopub.status.idle":"2024-05-14T14:32:06.942626Z","shell.execute_reply.started":"2024-05-14T14:32:06.933898Z","shell.execute_reply":"2024-05-14T14:32:06.941568Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Defining a function for padding sequences and packing batches**","metadata":{}},{"cell_type":"code","source":"# Define a function for padding sequences and packing batches\n# packet_fn specifies a function to control how batches are created from the individual data items\ndef packet_fn(batch):\n    # Unzip the batch to separate Latin and Bangla indices\n    latin, bangla = zip(*batch)\n#     print(latin, bangla)\n    # Pad the sequences of Latin indices\n    latin_padded = pad_sequence(latin, batch_first=True, padding_value=latin_token_to_index['<pad>'])\n#     print(latin_padded)\n    # Pad the sequences of Bangla indices\n    bangla_padded = pad_sequence(bangla, batch_first=True, padding_value=bangla_token_to_index['<pad>'])\n#     print(bangla_padded)\n    # Return the padded batches\n    return latin_padded, bangla_padded","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:08.465531Z","iopub.execute_input":"2024-05-14T14:32:08.466171Z","iopub.status.idle":"2024-05-14T14:32:08.471846Z","shell.execute_reply.started":"2024-05-14T14:32:08.466127Z","shell.execute_reply":"2024-05-14T14:32:08.470792Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# **Load training data into the AksharantarDataset and then creating the train_loader by Dataloader function**","metadata":{}},{"cell_type":"code","source":"# Load training data into the AksharantarDataset\ntrain_dataset = AksharantarDataset(latin_train, bangla_train, latin_token_to_index, bangla_token_to_index)\n# Create a DataLoader to batch and shuffle the dataset\n# packet_fn specifies a function to control how batches are created from the individual data items\ntrain_loader = DataLoader(train_dataset, batch_size = 64, collate_fn=packet_fn, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:09.726949Z","iopub.execute_input":"2024-05-14T14:32:09.727856Z","iopub.status.idle":"2024-05-14T14:32:09.732913Z","shell.execute_reply.started":"2024-05-14T14:32:09.727826Z","shell.execute_reply":"2024-05-14T14:32:09.731837Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# **Print an example from the dataset**","metadata":{}},{"cell_type":"code","source":"# Print an example from the dataset\nprint(train_dataset[4000])\n# for i,j in train_loader:\n#     print(i,'\\n\\n\\n',j)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:10.471233Z","iopub.execute_input":"2024-05-14T14:32:10.471559Z","iopub.status.idle":"2024-05-14T14:32:10.484552Z","shell.execute_reply.started":"2024-05-14T14:32:10.471535Z","shell.execute_reply":"2024-05-14T14:32:10.483481Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(tensor([19, 23,  7, 20,  5,  7, 22, 11, 16]), tensor([ 2, 17, 50, 43, 47, 56, 32, 51, 36,  0]))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n# **A function for calculating word accuracy per batch, ignoring the padding token**","metadata":{}},{"cell_type":"code","source":"# Define a word accuracy function for word-level accuracy\ndef word_accuracy(outputs, targets, ignore_index):\n    # Assuming outputs and targets are batched sequences of token indices\n    # Ignoring <pad> tokens as specified by `ignore_index`\n    correct = 0\n    total = 0\n    for out, tar in zip(outputs, targets):\n        # Ignoring padding in accuracy calculation\n#         print('out bef pad:',out)\n#         print('tar:',tar)\n        out = out[out != ignore_index]\n        tar = tar[tar != ignore_index]\n        ignore_index_eos = 0\n        out = out[out != ignore_index_eos]\n        tar = tar[tar != ignore_index_eos]\n#         print('out aft pad:',out)\n#         print('tar:',tar)\n        if torch.equal(out, tar):\n            correct += 1\n#             print('correct:',correct)\n        total += 1\n#         print('total:',total)\n    return correct / total if total > 0 else 0","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:11.238606Z","iopub.execute_input":"2024-05-14T14:32:11.239470Z","iopub.status.idle":"2024-05-14T14:32:11.246249Z","shell.execute_reply.started":"2024-05-14T14:32:11.239438Z","shell.execute_reply":"2024-05-14T14:32:11.245316Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"\n\n# **Defining the Training function**","metadata":{}},{"cell_type":"code","source":"\ndef train(model, iterator, optimizer, criterion, clip, device, ignore_index):\n    model.train()\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    for source, target in iterator:\n        source = source.to(device)\n        target = target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(source, target)\n        \n        output_dim = output.shape[-1]\n        # Slice to ignore the <sos> token and keep sequence structure\n        output = output[:, 1:, :]\n        target = target[:, 1:]\n        \n        # Flatten all dimensions except for the batch dimension for loss calculation\n        output_flat = output.reshape(-1, output_dim)\n        target_flat = target.reshape(-1)\n        \n#         print('trainnnnnnnn')\n        \n        loss = criterion(output_flat, target_flat)\n        # Calculate word-by-word accuracy\n        acc = word_accuracy(output.argmax(dim=2), target, ignore_index)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc\n    \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n######################","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:12.215536Z","iopub.execute_input":"2024-05-14T14:32:12.215865Z","iopub.status.idle":"2024-05-14T14:32:12.224307Z","shell.execute_reply.started":"2024-05-14T14:32:12.215841Z","shell.execute_reply":"2024-05-14T14:32:12.223357Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# **Defining the Evaluation function**","metadata":{"execution":{"iopub.status.busy":"2024-05-02T03:12:54.052339Z","iopub.execute_input":"2024-05-02T03:12:54.053023Z","iopub.status.idle":"2024-05-02T03:12:54.056815Z","shell.execute_reply.started":"2024-05-02T03:12:54.052993Z","shell.execute_reply":"2024-05-02T03:12:54.055862Z"}}},{"cell_type":"code","source":"def evaluate(model, iterator, criterion, device, ignore_index):\n    model.eval()\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    with torch.no_grad():\n        for source, target in iterator:\n            source = source.to(device)\n            target = target.to(device)\n            \n            output = model(source, target, 0)\n            output_dim = output.shape[-1]\n            output = output[:, 1:, :]\n            target = target[:, 1:]\n            \n            output_flat = output.reshape(-1, output_dim)\n            target_flat = target.reshape(-1)\n#             print('vallllllll')\n            loss = criterion(output_flat, target_flat)\n            acc = word_accuracy(output.argmax(dim=2), target, ignore_index)\n            \n            epoch_loss += loss.item()\n            epoch_acc += acc\n            \n#             break\n    \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n#######################","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:13.198128Z","iopub.execute_input":"2024-05-14T14:32:13.198518Z","iopub.status.idle":"2024-05-14T14:32:13.206447Z","shell.execute_reply.started":"2024-05-14T14:32:13.198490Z","shell.execute_reply":"2024-05-14T14:32:13.205590Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# **Load validation data into the AksharantarDataset and then creating the valid_loader by Dataloader function**","metadata":{}},{"cell_type":"code","source":"# Load validation data by reading a CSV file\nlatin_valid, bangla_valid = load_data('/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_valid.csv')\n\n# Create a validation dataset using the AksharantarDataset class.\nvalid_dataset = AksharantarDataset(latin_valid, bangla_valid, latin_token_to_index, bangla_token_to_index)\n\n# Create a DataLoader to batch and shuffle the dataset\n# 'collate_fn=packet_fn' specifies a function to control how batches are created from the individual data items.\n# 'shuffle=True' ensures that the data is shuffled at every epoch which helps to reduce model overfitting\nvalid_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=packet_fn, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:14.273687Z","iopub.execute_input":"2024-05-14T14:32:14.274312Z","iopub.status.idle":"2024-05-14T14:32:14.295205Z","shell.execute_reply.started":"2024-05-14T14:32:14.274280Z","shell.execute_reply":"2024-05-14T14:32:14.294400Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# **The training process for specified number of epochs**","metadata":{}},{"cell_type":"code","source":"INPUT_DIM = 100\nOUTPUT_DIM = 100\nENC_EMB_DIM = 256\nDEC_EMB_DIM = 256\nHID_DIM = 512\nENC_LAYERS = 1\nDEC_LAYERS = 3\nENC_RNN_CELL = 'gru'\nDEC_RNN_CELL = 'gru'\n\nencoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL,dropout=0.3, bidirectional = True)\ndecoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout=0.3, bidirectional = True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nmodel = Seq_to_Seq(encoder, decoder).to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:17.231574Z","iopub.execute_input":"2024-05-14T14:32:17.232486Z","iopub.status.idle":"2024-05-14T14:32:17.302107Z","shell.execute_reply.started":"2024-05-14T14:32:17.232445Z","shell.execute_reply":"2024-05-14T14:32:17.301208Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(256, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(256, 512, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting the number of epochs the training process should run\nNUM_EPOCHS = 1\n# Set the maximum norm of the gradients to 1 to prevent exploding gradients\nCLIP = 1\n# Initialize the optimizer, Adam\noptimizer = torch.optim.Adam(model.parameters())\n# Padding token index should be ignored in loss calculation\nignore_index = bangla_token_to_index['<pad>']\n# Define the loss function with 'ignore_index' to avoid affecting loss calculation with padding tokens\ncriterion = nn.CrossEntropyLoss(ignore_index=ignore_index).to(device)\n\n# Start the training process for the defined number of epochs\nfor epoch in range(NUM_EPOCHS):\n    # Doing training on the train dataset and return average loss and accuracy\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n    # Evaluating the model on the validation dataset and return average loss and accuracy\n    val_loss, val_accuracy = evaluate(model, valid_loader, criterion, device, ignore_index)\n    \n    # Print the loss and accuracy for each epoch\n    print(f'Epoch: {epoch+1}')\n    print(f'\\tTrain_Loss: {train_loss:.3f}, Train_Accuracy: {train_accuracy*100:.2f}%')\n    print(f'\\tVal_Loss: {val_loss:.3f},  Val_Accuracy: {val_accuracy*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:15:13.681238Z","iopub.execute_input":"2024-05-14T14:15:13.681620Z","iopub.status.idle":"2024-05-14T14:16:00.821247Z","shell.execute_reply.started":"2024-05-14T14:15:13.681589Z","shell.execute_reply":"2024-05-14T14:16:00.820295Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch: 1\n\tTrain_Loss: 1.868, Train_Accuracy: 2.26%\n\tVal_Loss: 1.504,  Val_Accuracy: 10.96%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Load the Test data into the AksharantarDataset and then creating the test_loader by Dataloader function**","metadata":{}},{"cell_type":"code","source":"# Load the test data from the specified CSV file location\nlatin_test, bangla_test = load_data('/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_test.csv')\n\n# Create test_dataset using the AksharantarDataset class, initializing it with test data\n# and corresponding token-to-index mappings for both Latin and Bangla scripts\ntest_dataset = AksharantarDataset(latin_test, bangla_test, latin_token_to_index, bangla_token_to_index)\n\n# A DataLoader for the test dataset. Here, the batch size is set to 1, indicates\n# that the model will process one item at a time. This is for testing to make\n# detailed predictions per sample without batching effects.\ntest_loader = DataLoader(test_dataset, batch_size=32, collate_fn=packet_fn, shuffle=False)\n# print(test_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:17:31.796751Z","iopub.execute_input":"2024-05-14T14:17:31.797350Z","iopub.status.idle":"2024-05-14T14:17:31.832104Z","shell.execute_reply.started":"2024-05-14T14:17:31.797319Z","shell.execute_reply":"2024-05-14T14:17:31.831231Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"\n\n# **A function to convert an array of indices back into a string, excluding any indices corresponding to special tokens like padding, start, or end of sequence tokens, which should not appear in the final output string**","metadata":{}},{"cell_type":"code","source":"def decode_indices(indices, index_to_token):\n    # Filter out indices for padding, start-of-sequence, and end-of-sequence tokens to ensure only valid character indices are decoded\n    valid_indices = [index for index in indices if index in index_to_token and index not in (bangla_token_to_index['<pad>'], bangla_token_to_index['<sos>'], bangla_token_to_index['<eos>'])]\n    # Convert each index to its corresponding character and join them to form the decoded string\n    return ''.join([index_to_token[index] for index in valid_indices])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:17:32.159988Z","iopub.execute_input":"2024-05-14T14:17:32.160342Z","iopub.status.idle":"2024-05-14T14:17:32.165938Z","shell.execute_reply.started":"2024-05-14T14:17:32.160313Z","shell.execute_reply":"2024-05-14T14:17:32.164903Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# **Creating the prediction function to generate outputs for all samples in the test_loader**","metadata":{}},{"cell_type":"code","source":"def predict(model, iterator, device):\n    # Set the model to evaluation mode to disable dropout or batch normalization effects during inference\n    model.eval()\n    predictions = []\n    # Disables gradient calculations for performance improvement since they are not needed in inference\n    with torch.no_grad():\n        for source, target in iterator:\n            # Ensure the source and target tensors are on the correct device (GPU or CPU)\n            source = source.to(device)\n            target = target.to(device)\n            # Obtain model output without teacher forcing (i.e., the model relies entirely on its predictions)\n            output = model(source, target, 0)\n            # Get the index with the highest probability from output predictions\n            output = output.argmax(2)\n            # Convert tensors to CPU numpy arrays for easier manipulation and extraction\n            source = source.cpu().numpy()\n            output = output.cpu().numpy()\n            target = target.cpu().numpy()\n            # Store the tuple of source and decoded output predictions\n            predictions.append((source, target, output))\n    # Return all predictions made over the iterator\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:17:32.642689Z","iopub.execute_input":"2024-05-14T14:17:32.643351Z","iopub.status.idle":"2024-05-14T14:17:32.651354Z","shell.execute_reply.started":"2024-05-14T14:17:32.643318Z","shell.execute_reply":"2024-05-14T14:17:32.650258Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# **Creating dictionaries to map indices back to its corresponding characters**","metadata":{}},{"cell_type":"code","source":"# Create dictionaries to map indices back to characters, observing the interpretation of prediction outputs\nlatin_index_to_token = {index: char for char, index in latin_token_to_index.items()}\nbangla_index_to_token = {index: char for char, index in bangla_token_to_index.items()}\n# print(latin_index_to_token)\n# print(bangla_index_to_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:17:33.334235Z","iopub.execute_input":"2024-05-14T14:17:33.334737Z","iopub.status.idle":"2024-05-14T14:17:33.339901Z","shell.execute_reply.started":"2024-05-14T14:17:33.334702Z","shell.execute_reply":"2024-05-14T14:17:33.338845Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# **Displaying results: Each input text from the test dataset and its corresponding predicted output text are printed. This helps in visually assessing the accuracy and quality of the transliterations produced by the model**","metadata":{}},{"cell_type":"code","source":"# Taking the prediction function to generate outputs for all samples in the test_loader\ntest_predictions = predict(model, test_loader, device)\n# print(test_predictions[1])\n# Loop through the list of tuples containing source and output indices from the test predictions\nfor source_indices, target_indices, output_indices in test_predictions:\n    # Iterate through each example in the batch. This is necessary as batches may contain multiple examples\n    for i in range(source_indices.shape[0]):\n        # Decode the source indices to their corresponding text using the mapping dictionary for Latin script\n        input_text = decode_indices(source_indices[i], latin_index_to_token)\n        \n        target_text = decode_indices(target_indices[i], bangla_index_to_token)\n\n        # Decode the output indices to their corresponding text using the mapping dictionary for Bangla script\n        predicted_text = decode_indices(output_indices[i], bangla_index_to_token)\n        # Print the original input text and its corresponding predicted transliteration\n        print(f'Input Text: {input_text} -> Actual Text: {target_text} -> Predicted Text: {predicted_text}')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:18:01.535738Z","iopub.execute_input":"2024-05-14T14:18:01.536612Z","iopub.status.idle":"2024-05-14T14:18:01.541117Z","shell.execute_reply.started":"2024-05-14T14:18:01.536578Z","shell.execute_reply":"2024-05-14T14:18:01.540166Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random\n\n# key = input('Enter your API:')\nwandb.login(key='25c2257eaf6c22aa056893db14da4ee2bf0a531a')  #25c2257eaf6c22aa056893db14da4ee2bf0a531a","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:32:24.407715Z","iopub.execute_input":"2024-05-14T14:32:24.408037Z","iopub.status.idle":"2024-05-14T14:32:28.858884Z","shell.execute_reply.started":"2024-05-14T14:32:24.408013Z","shell.execute_reply":"2024-05-14T14:32:28.857936Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep all final new 1',\n    'metric': {\n        'name': 'Val_Accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'input_embed_size': {\n            'values': [16,32,64,256,512]\n        },\n        'num_enc_layers':{\n            'values': [1,2,3]\n        },\n        'num_dec_layers':{\n            'values': [1,2,3]\n        },\n        'hid_layer_size': {\n            'values': [16,32,64,256,512]\n        },\n        'cell_type': {\n            'values': ['rnn', 'gru', 'lstm']\n        },\n        'bidirectional':{\n            'values': [True, False]\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n#       'beam search in decoder with different beam sizes': \n    }\n}\n\nsweep_id = wandb.sweep(sweep = sweep_config, project=\"Deep_Learning_A3\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:43:36.275430Z","iopub.execute_input":"2024-05-14T14:43:36.276081Z","iopub.status.idle":"2024-05-14T14:43:37.195033Z","shell.execute_reply.started":"2024-05-14T14:43:36.276050Z","shell.execute_reply":"2024-05-14T14:43:37.193964Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Create sweep with ID: r263yuz3\nSweep URL: https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\ndef main():\n    # Initialize a new wandb run\n    with wandb.init() as run:\n        # Construct run name from configuration\n        run_name = \"-embed_size-\"+str(wandb.config.input_embed_size)+\"-layers_enc-\"+str(wandb.config.num_enc_layers)+\"-layers_dec-\"+str(wandb.config.num_dec_layers)+\"-hid_size-\"+str(wandb.config.hid_layer_size)+\"-cell_type-\"+wandb.config.cell_type+\"-bidirectional-\"+str(wandb.config.bidirectional)+\"-dropout-\"+str(wandb.config.dropout)\n        wandb.run.name = run_name\n\n        # Constants defining the dimensions of the input and output character sets\n        INPUT_DIM = 100  # size of the Latin character set\n        OUTPUT_DIM = 100  # size of the Bangla character set\n\n        # Constants defining the dimensions of the embeddings for encoder and decoder\n        ENC_EMB_DIM = wandb.config.input_embed_size  # Encoder embedding dimension\n        DEC_EMB_DIM = wandb.config.input_embed_size  # Decoder embedding dimension\n\n        # Constants defining the dimension of the hidden layers for encoder and decoder\n        HID_DIM = wandb.config.hid_layer_size  # Hidden dimension size\n\n        # Constants defining the number of layers for encoder and decoder\n        ENC_LAYERS = wandb.config.num_enc_layers  # Number of layers in the encoder\n        DEC_LAYERS = wandb.config.num_dec_layers  # Number of layers in the decoder\n        \n\n        # Constants defining the type of RNN cell to use for encoder and decoder\n        ENC_RNN_CELL = wandb.config.cell_type  # RNN cell type for the encoder\n        DEC_RNN_CELL = wandb.config.cell_type  # RNN cell type for the decoder\n\n        # Instantiate the encoder with specified configurations\n        encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL, dropout = wandb.config.dropout, bidirectional = wandb.config.bidirectional)\n        # Instantiate the decoder with specified configurations\n        decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout = wandb.config.dropout, bidirectional = wandb.config.bidirectional)\n\n        # Determine the computing device (CUDA if available, otherwise CPU)\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        # Print the device will be used\n        print(f\"Using device: {device}\")\n\n        # Instantiate the Seq_to_Seq model and move it to the chosen computing device\n        model = Seq_to_Seq(encoder, decoder).to(device)\n        print(model)\n        \n        \n        # Setting the number of epochs the training process should run\n        NUM_EPOCHS = 7\n        # Set the maximum norm of the gradients to 1 to prevent exploding gradients\n        CLIP = 1\n        # Initialize the optimizer, Adam\n        optimizer = torch.optim.Adam(model.parameters())\n        # Padding token index should be ignored in loss calculation\n        ignore_index = bangla_token_to_index['<pad>']\n        # Define the loss function with 'ignore_index' to avoid affecting loss calculation with padding tokens\n        criterion = nn.CrossEntropyLoss(ignore_index=ignore_index).to(device)\n\n        # Start the training process for the defined number of epochs\n        for epoch in range(NUM_EPOCHS):\n            # Doing training on the train dataset and return average loss and accuracy\n            train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n            # Evaluating the model on the validation dataset and return average loss and accuracy\n            val_loss, val_accuracy = evaluate(model, valid_loader, criterion, device, ignore_index)\n\n            # Print the loss and accuracy for each epoch\n            print(f'Epoch: {epoch+1}')\n            print(f'\\tTrain_Loss: {train_loss:.3f}, Train_Accuracy: {train_accuracy*100:.2f}%')\n            print(f'\\tVal_Loss: {val_loss:.3f},  Val_Accuracy: {val_accuracy*100:.2f}%')\n            wandb.log({\"train_accuracy\": train_accuracy * 100, \"training_loss\": train_loss})\n            wandb.log({\"Val_Accuracy\": val_accuracy * 100, \"Val_Loss\": val_loss})\n\n\nwandb.agent(sweep_id, function=main, count=30)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T14:43:41.174959Z","iopub.execute_input":"2024-05-14T14:43:41.175730Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8i0qu3xs with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240514_144344-8i0qu3xs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/8i0qu3xs' target=\"_blank\">vocal-sweep-1</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/8i0qu3xs' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/8i0qu3xs</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(64, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(64, 512, batch_first=True)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 1.803, Train_Accuracy: 2.95%\n\tVal_Loss: 1.448,  Val_Accuracy: 9.45%\nEpoch: 2\n\tTrain_Loss: 1.068, Train_Accuracy: 8.94%\n\tVal_Loss: 1.270,  Val_Accuracy: 18.29%\nEpoch: 3\n\tTrain_Loss: 0.863, Train_Accuracy: 14.12%\n\tVal_Loss: 1.231,  Val_Accuracy: 19.87%\nEpoch: 4\n\tTrain_Loss: 0.743, Train_Accuracy: 13.85%\n\tVal_Loss: 1.200,  Val_Accuracy: 22.02%\nEpoch: 5\n\tTrain_Loss: 0.673, Train_Accuracy: 17.71%\n\tVal_Loss: 1.204,  Val_Accuracy: 24.83%\nEpoch: 6\n\tTrain_Loss: 0.622, Train_Accuracy: 21.37%\n\tVal_Loss: 1.169,  Val_Accuracy: 28.47%\nEpoch: 7\n\tTrain_Loss: 0.571, Train_Accuracy: 19.01%\n\tVal_Loss: 1.167,  Val_Accuracy: 26.39%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▄▅▆▇█▇</td></tr><tr><td>Val_Loss</td><td>█▄▃▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▅▇█▇</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>26.3916</td></tr><tr><td>Val_Loss</td><td>1.16718</td></tr><tr><td>train_accuracy</td><td>19.00586</td></tr><tr><td>training_loss</td><td>0.57141</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vocal-sweep-1</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/8i0qu3xs' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/8i0qu3xs</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240514_144344-8i0qu3xs/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pbedc6qw with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240514_144820-pbedc6qw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pbedc6qw' target=\"_blank\">confused-sweep-2</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pbedc6qw' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pbedc6qw</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(16, 8, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(16, 32, batch_first=True)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.194, Train_Accuracy: 0.00%\n\tVal_Loss: 2.941,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.897, Train_Accuracy: 0.00%\n\tVal_Loss: 2.860,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.824, Train_Accuracy: 0.00%\n\tVal_Loss: 2.805,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.779, Train_Accuracy: 0.00%\n\tVal_Loss: 2.820,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.747, Train_Accuracy: 0.00%\n\tVal_Loss: 2.740,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.712, Train_Accuracy: 0.00%\n\tVal_Loss: 2.687,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.690, Train_Accuracy: 0.00%\n\tVal_Loss: 2.766,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▆▄▅▂▁▃</td></tr><tr><td>train_accuracy</td><td>▁██▁█▁█</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>2.76573</td></tr><tr><td>train_accuracy</td><td>0.00195</td></tr><tr><td>training_loss</td><td>2.69032</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">confused-sweep-2</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pbedc6qw' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pbedc6qw</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240514_144820-pbedc6qw/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g38l4pdo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240514_145239-g38l4pdo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/g38l4pdo' target=\"_blank\">fresh-sweep-3</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/r263yuz3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/g38l4pdo' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/g38l4pdo</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(64, 32, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(64, 32, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.256, Train_Accuracy: 0.00%\n\tVal_Loss: 3.163,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.964, Train_Accuracy: 0.00%\n\tVal_Loss: 3.060,  Val_Accuracy: 0.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}