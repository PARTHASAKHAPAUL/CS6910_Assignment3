{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8151136,"sourceType":"datasetVersion","datasetId":4820823},{"sourceId":8427323,"sourceType":"datasetVersion","datasetId":5018092}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing all the necessary libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:45:37.776751Z","iopub.execute_input":"2024-05-17T12:45:37.777495Z","iopub.status.idle":"2024-05-17T12:45:37.782929Z","shell.execute_reply.started":"2024-05-17T12:45:37.777461Z","shell.execute_reply":"2024-05-17T12:45:37.781853Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## **Encoder class**","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, rnn_cell='lstm', dropout=0.5, bidirectional=True):\n        super(Encoder, self).__init__()  # Initialize the parent class.\n        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)  # Create an embedding layer.\n        self.dropout = nn.Dropout(dropout)  # Create a dropout layer.\n        self.hidden_size = hidden_size  # Store the hidden size.\n        self.num_layers = num_layers  # Store the number of layers.\n        self.bidirectional = bidirectional  # Store whether the RNN is bidirectional.\n        \n        rnn_hidden_size = hidden_size // 2 if bidirectional else hidden_size  # Adjust hidden size for bidirectional RNN.\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)  # Create an LSTM layer.\n        elif rnn_cell.lower() == 'gru':\n            self.rnn = nn.GRU(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)  # Create a GRU layer.\n        else:\n            self.rnn = nn.RNN(embedding_size, rnn_hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout), bidirectional=bidirectional)  # Create an RNN layer.\n    \n    def forward(self, x):\n        embedded = self.embedding(x)  # Embed the input sequences.\n        embedded = self.dropout(embedded)  # Apply dropout to the embeddings.\n        outputs, hidden = self.rnn(embedded)  # Pass the embeddings through the RNN.\n\n        if self.bidirectional:  # If the RNN is bidirectional.\n            if isinstance(hidden, tuple):  # If the hidden state is a tuple (LSTM case).\n                h_n, c_n = hidden  # Unpack the hidden states (hidden and cell states for LSTM).\n#                 print('enc h bef dir',h_n.shape)  \n#                 print('enc c bef dir',c_n.shape)  \n                h_n = torch.cat((h_n[0::2], h_n[1::2]), dim=2)  # Concatenate the forward and backward hidden states.\n                c_n = torch.cat((c_n[0::2], c_n[1::2]), dim=2)  # Concatenate the forward and backward cell states.\n#                 print('enc h af dir',h_n.shape) \n#                 print('enc c af dir',c_n.shape)  \n                hidden = (h_n, c_n)  # Pack the adjusted hidden states back into a tuple.\n            else:  # If the hidden state is not a tuple (GRU/RNN case).\n#                 print('enc hidd bef dir',hidden.shape) \n                hidden = torch.cat((hidden[0::2], hidden[1::2]), dim=2)  # Concatenate the forward and backward hidden states.\n#                 print('after dir enc:',hidden.shape) \n\n        return hidden  # Return the RNN hidden states.\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:28.463896Z","iopub.execute_input":"2024-05-17T12:59:28.464293Z","iopub.status.idle":"2024-05-17T12:59:28.479193Z","shell.execute_reply.started":"2024-05-17T12:59:28.464264Z","shell.execute_reply":"2024-05-17T12:59:28.478151Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"markdown","source":"# **Decoder class**","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers, encoder_num_layers, rnn_cell='lstm', dropout=0.5, bidirectional=True):\n        super(Decoder, self).__init__()  # Initialize the parent class.\n        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)  # Create an embedding layer.\n        self.dropout = nn.Dropout(dropout)  # Create a dropout layer.\n        self.output_size = output_size  # Store the output size.\n        self.hidden_size = hidden_size * encoder_num_layers if bidirectional else hidden_size  # Adjust hidden size for bidirectional encoder.\n        self.num_layers = num_layers  # Store the number of layers.\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))  # Create an LSTM layer.\n        elif rnn_cell.lower() == 'gru':\n            self.rnn = nn.GRU(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))  # Create a GRU layer.\n        else:\n            self.rnn = nn.RNN(embedding_size, self.hidden_size, num_layers, batch_first=True, dropout=(0 if num_layers == 1 else dropout))  # Create an RNN layer.\n        \n        self.fc = nn.Linear(self.hidden_size, output_size)  # Create a fully connected layer for output.\n\n    def forward(self, x, hidden):\n        x = x.unsqueeze(1)  # Add a singleton dimension to the input tensor.\n        embedded = self.dropout(self.embedding(x))  # Embed the input sequences and apply dropout.\n        output, hidden = self.rnn(embedded, hidden)  # Pass the embedded input through the RNN.\n        output = self.fc(self.dropout(output.squeeze(1)))  # Apply dropout and pass through the fully connected layer.\n        return output, hidden  # Return the output and hidden states.\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:29.032444Z","iopub.execute_input":"2024-05-17T12:59:29.033401Z","iopub.status.idle":"2024-05-17T12:59:29.045193Z","shell.execute_reply.started":"2024-05-17T12:59:29.033365Z","shell.execute_reply":"2024-05-17T12:59:29.044011Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"# **Sequence to Sequence model for the above encoder and decoder**","metadata":{}},{"cell_type":"code","source":"class Seq_to_Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq_to_Seq, self).__init__()  # Initialize the parent class.\n        self.encoder = encoder  # Store the encoder module.\n        self.decoder = decoder  # Store the decoder module.\n\n    def forward(self, source, target, teaching_force_ratio=0.5):\n        batch_size = source.size(0)  # Get the batch size.\n        target_len = target.size(1)  # Get the target sequence length.\n        target_vocab_size = self.decoder.output_size  # Get the output vocabulary size.\n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(source.device)  # Initialize output tensor.\n        \n        encoder_hidden = self.encoder(source)  # Get encoder hidden states.\n        \n        if isinstance(encoder_hidden, tuple):  # If encoder hidden states is a tuple (LSTM case).\n            h_n, c_n = encoder_hidden  # Unpack hidden states.\n            if self.encoder.bidirectional:  # If encoder is bidirectional.\n                h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)  # Concatenate forward and backward hidden states.\n                c_n = torch.cat([c_n[i:i+1] for i in range(0, c_n.shape[0], 2)] + [c_n[i:i+1] for i in range(1, c_n.shape[0], 2)], dim=2)  # Concatenate forward and backward cell states.\n            \n            if h_n.size(0) < self.decoder.num_layers:  # If decoder has more layers than encoder.\n                zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=h_n.device)  # Create zero tensor for hidden states.\n                zero_c = torch.zeros(self.decoder.num_layers - c_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=c_n.device)  # Create zero tensor for cell states.\n                h_n = torch.cat([h_n, zero_h], dim=0)  # Concatenate zero tensor to adjust hidden states shape.\n                c_n = torch.cat([c_n, zero_c], dim=0)  # Concatenate zero tensor to adjust cell states shape.\n            encoder_hidden = (h_n[:self.decoder.num_layers], c_n[:self.decoder.num_layers])  # Update encoder hidden states.\n        else:  # If encoder hidden states is not a tuple (GRU/RNN case).\n            h_n = encoder_hidden  # Use hidden states directly.\n            if self.encoder.bidirectional:  # If encoder is bidirectional.\n                h_n = torch.cat([h_n[i:i+1] for i in range(0, h_n.shape[0], 2)] + [h_n[i:i+1] for i in range(1, h_n.shape[0], 2)], dim=2)  # Concatenate forward and backward hidden states.\n            if h_n.size(0) < self.decoder.num_layers:  # If decoder has more layers than encoder.\n                zero_h = torch.zeros(self.decoder.num_layers - h_n.size(0), batch_size, self.encoder.num_layers * self.encoder.hidden_size, device=encoder_hidden.device)  # Create zero tensor for hidden states.\n                h_n = torch.cat([h_n, zero_h], dim=0)  # Concatenate zero tensor to adjust hidden states shape.\n            encoder_hidden = h_n[:self.decoder.num_layers]  # Update encoder hidden states.\n        \n        decoder_input = target[:, 0]  # Get the decoder input for the first time step.\n                    \n        for t in range(1, target_len):  # Iterate over target sequence.\n            decoder_output, encoder_hidden = self.decoder(decoder_input, encoder_hidden)  # Get decoder output and update hidden states.\n            outputs[:, t] = decoder_output  # Store decoder output.\n            teacher_force = torch.rand(1) < teaching_force_ratio  # Determine whether to use teacher forcing.\n            top1 = decoder_output.argmax(1)  # Get the predicted token.\n            decoder_input = target[:, t] if teacher_force else top1  # Update decoder input based on teacher forcing.\n\n        return outputs  # Return the final output tensor.\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:29.629687Z","iopub.execute_input":"2024-05-17T12:59:29.630031Z","iopub.status.idle":"2024-05-17T12:59:29.649990Z","shell.execute_reply.started":"2024-05-17T12:59:29.630004Z","shell.execute_reply":"2024-05-17T12:59:29.649056Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"markdown","source":"# **Printing the model**","metadata":{}},{"cell_type":"code","source":"INPUT_DIM = 100  # Set the size of the input vocabulary.\nOUTPUT_DIM = 100  # Set the size of the output vocabulary.\nENC_EMB_DIM = 256  # Set the dimension of the input embeddings.\nDEC_EMB_DIM = 256  # Set the dimension of the output embeddings.\nHID_DIM = 512  # Set the dimension of the hidden states.\nENC_LAYERS = 1  # Set the number of layers in the encoder.\nDEC_LAYERS = 3  # Set the number of layers in the decoder.\nENC_RNN_CELL = 'gru'  # Specify the RNN cell type for the encoder.\nDEC_RNN_CELL = 'gru'  # Specify the RNN cell type for the decoder.\n\nencoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL, dropout=0.3, bidirectional=True)  # Initialize the encoder module.\ndecoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout=0.3, bidirectional=True)  # Initialize the decoder module.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Choose the appropriate device for computation.\nprint(f\"Using device: {device}\")  # Print the chosen device.\nmodel = Seq_to_Seq(encoder, decoder).to(device)  # Initialize the sequence-to-sequence model and move it to the selected device.\nprint(model)  # Print the model summary.\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:30.058945Z","iopub.execute_input":"2024-05-17T12:59:30.059834Z","iopub.status.idle":"2024-05-17T12:59:30.126274Z","shell.execute_reply.started":"2024-05-17T12:59:30.059798Z","shell.execute_reply":"2024-05-17T12:59:30.125191Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(256, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): GRU(256, 512, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **A function to create a vocabulary set from the given text**","metadata":{}},{"cell_type":"code","source":"\n# Define a function to create a vocabulary set from a given text\ndef create_vocab(text):\n    # Create a set of unique characters found in the text\n    # Each word in the text is processed to extract its characters\n    vocab = set(char for word in text for char in word)\n    # Add a padding token to the vocabulary\n    vocab.add('<pad>')\n    # Add a start-of-sequence token to the vocabulary\n    vocab.add('<sos>')  # Start of sequence token\n    # Add an end-of-sequence token to the vocabulary\n    vocab.add('<eos>')  # End of sequence token\n    # Return the complete set of vocabulary items\n    return vocab","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:30.441790Z","iopub.execute_input":"2024-05-17T12:59:30.442146Z","iopub.status.idle":"2024-05-17T12:59:30.447846Z","shell.execute_reply.started":"2024-05-17T12:59:30.442122Z","shell.execute_reply":"2024-05-17T12:59:30.446902Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"markdown","source":"# **A function to load data from a CSV file**","metadata":{}},{"cell_type":"code","source":"# Define a function to load data from a CSV file\ndef load_data(path):\n    # The file has no header and columns are named as 'latin' and 'bangla'\n    df = pd.read_csv(path, header=None, names=['latin', 'bangla'])\n#     df = df.head(10)\n    # Return the columns as two separate Series objects\n    return df['latin'], df['bangla']","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.160528Z","iopub.execute_input":"2024-05-17T12:59:31.160914Z","iopub.status.idle":"2024-05-17T12:59:31.167644Z","shell.execute_reply.started":"2024-05-17T12:59:31.160886Z","shell.execute_reply":"2024-05-17T12:59:31.166602Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"# **Load Latin and bangla training data**","metadata":{}},{"cell_type":"code","source":"# Load Latin and bangla training data from specified path\nlatin_train, bangla_train = load_data('/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.224482Z","iopub.execute_input":"2024-05-17T12:59:31.224879Z","iopub.status.idle":"2024-05-17T12:59:31.317640Z","shell.execute_reply.started":"2024-05-17T12:59:31.224844Z","shell.execute_reply":"2024-05-17T12:59:31.316825Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"# **Print the loaded Latin and Bangla training data**","metadata":{}},{"cell_type":"code","source":"# Print the loaded Latin training data\nprint(latin_train)\nprint()\n# Print the loaded bangla training data\nprint(bangla_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.319292Z","iopub.execute_input":"2024-05-17T12:59:31.319604Z","iopub.status.idle":"2024-05-17T12:59:31.327216Z","shell.execute_reply.started":"2024-05-17T12:59:31.319579Z","shell.execute_reply":"2024-05-17T12:59:31.326236Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"0        namdharirao\n1        hindukusher\n2        farajikandi\n3           moubarak\n4             chiung\n            ...     \n51195       silmadar\n51196        jonnote\n51197      handibage\n51198         borpar\n51199     bideshikei\nName: latin, Length: 51200, dtype: object\n\n0            নামধারীরাও\n1           হিন্দুকুশের\n2           ফরাজীকান্দি\n3                মুবারক\n4                চিয়ুং\n              ...      \n51195          সিলমাদার\n51196            জন্যতে\n51197    হ্যান্ডিব্যাগে\n51198             বরপার\n51199         বিদেশীকেই\nName: bangla, Length: 51200, dtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Create two vocabularies from the Latin and Bangla training data**","metadata":{}},{"cell_type":"code","source":"# Create a vocabulary from the Latin training data\nlatin_vocab = create_vocab(latin_train)\n# Create a vocabulary from the bangla training data\nbangla_vocab = create_vocab(bangla_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.347287Z","iopub.execute_input":"2024-05-17T12:59:31.347601Z","iopub.status.idle":"2024-05-17T12:59:31.449095Z","shell.execute_reply.started":"2024-05-17T12:59:31.347569Z","shell.execute_reply":"2024-05-17T12:59:31.448051Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"# **Print the created Latin and Bangla vocabularies**","metadata":{}},{"cell_type":"code","source":"# Print the created Latin vocabulary\nprint(latin_vocab)\nprint()\n# Print the created bangla vocabulary\nprint(bangla_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.451113Z","iopub.execute_input":"2024-05-17T12:59:31.451494Z","iopub.status.idle":"2024-05-17T12:59:31.457187Z","shell.execute_reply.started":"2024-05-17T12:59:31.451460Z","shell.execute_reply":"2024-05-17T12:59:31.456238Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"{'o', '<eos>', 'j', 'g', 'l', 'e', 'd', 'm', 'v', '<sos>', 'p', 'z', 'r', 'y', 'w', 'q', '<pad>', 'k', 'n', 'c', 'i', 'h', 'x', 'a', 'u', 'f', 't', 'b', 's'}\n\n{'ট', 'ঙ', 'চ', 'ি', 'ফ', 'ল', 'ম', '<eos>', 'শ', 'ড', 'ঁ', 'ও', 'খ', 'ঐ', 'স', 'ঋ', 'ঠ', 'ক', 'য', 'আ', 'উ', '্', 'হ', 'র', 'ছ', 'ং', 'দ', 'এ', 'ূ', 'ঘ', 'ৃ', 'ঊ', '<sos>', 'ঝ', 'ত', 'ষ', '়', 'ৌ', 'ণ', 'া', 'ে', '২', '<pad>', 'ো', 'গ', 'ৎ', 'ধ', 'ঈ', 'ৈ', 'ভ', 'ই', 'ঃ', 'ু', 'ন', 'ব', 'ী', 'অ', 'ঔ', 'ঞ', 'প', 'থ', 'ঢ', 'জ'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Map each token in the Latin and Bangla vocabularies to a unique index and then Print the dictionaries mapping (Latin tokens to indices) and (Bangla tokens to indices)**\n","metadata":{}},{"cell_type":"code","source":"# Map each token in the Latin vocabulary to a unique index\nlatin_token_to_index = {token: index for index, token in enumerate(sorted(latin_vocab))}\n# Map each token in the bangla vocabulary to a unique index\nbangla_token_to_index = {token: index for index, token in enumerate(sorted(bangla_vocab))}\n\n# Print the dictionary mapping Latin tokens to indices\nprint(latin_token_to_index)\nprint()\n\n# Print the dictionary mapping bangla tokens to indices\nprint(bangla_token_to_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.485206Z","iopub.execute_input":"2024-05-17T12:59:31.485486Z","iopub.status.idle":"2024-05-17T12:59:31.491880Z","shell.execute_reply.started":"2024-05-17T12:59:31.485464Z","shell.execute_reply":"2024-05-17T12:59:31.490861Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"{'<eos>': 0, '<pad>': 1, '<sos>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n\n{'<eos>': 0, '<pad>': 1, '<sos>': 2, 'ঁ': 3, 'ং': 4, 'ঃ': 5, 'অ': 6, 'আ': 7, 'ই': 8, 'ঈ': 9, 'উ': 10, 'ঊ': 11, 'ঋ': 12, 'এ': 13, 'ঐ': 14, 'ও': 15, 'ঔ': 16, 'ক': 17, 'খ': 18, 'গ': 19, 'ঘ': 20, 'ঙ': 21, 'চ': 22, 'ছ': 23, 'জ': 24, 'ঝ': 25, 'ঞ': 26, 'ট': 27, 'ঠ': 28, 'ড': 29, 'ঢ': 30, 'ণ': 31, 'ত': 32, 'থ': 33, 'দ': 34, 'ধ': 35, 'ন': 36, 'প': 37, 'ফ': 38, 'ব': 39, 'ভ': 40, 'ম': 41, 'য': 42, 'র': 43, 'ল': 44, 'শ': 45, 'ষ': 46, 'স': 47, 'হ': 48, '়': 49, 'া': 50, 'ি': 51, 'ী': 52, 'ু': 53, 'ূ': 54, 'ৃ': 55, 'ে': 56, 'ৈ': 57, 'ো': 58, 'ৌ': 59, '্': 60, 'ৎ': 61, '২': 62}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Defining a Dataset class for handling Latin and Bangla word pairs**","metadata":{}},{"cell_type":"code","source":"# Define a Dataset class for handling Latin and Bangla word pairs\nclass AksharantarDataset(Dataset):\n    def __init__(self, latin_words, bangla_words, latin_token_to_index, bangla_token_to_index):\n        # Store the lists of Latin and Bangla words\n        self.latin_words = latin_words\n        self.bangla_words = bangla_words\n        # Store the dictionaries that map characters to indices for both languages\n        self.latin_token_to_index = latin_token_to_index\n        self.bangla_token_to_index = bangla_token_to_index\n\n    def __len__(self):\n        # Return the number of word pairs in the dataset\n        return len(self.latin_words)\n\n    def __getitem__(self, index):\n        # Fetching the Latin and Bangla words at the specified index\n        latin_word = self.latin_words.iloc[index]\n#         print(latin_word)\n        bangla_word = self.bangla_words.iloc[index]\n#         print(bangla_word)\n        # Convert the Latin word into indices using the latin_token_to_index mapping\n        latin_indices = [latin_token_to_index[char] for char in latin_word]\n#         print(latin_indices)\n        # Convert the Bangla word into indices, adding <sos> and <eos> tokens\n        bangla_indices = [bangla_token_to_index['<sos>']] + [bangla_token_to_index[char] for char in bangla_word] + [bangla_token_to_index['<eos>']]\n#         print(bangla_indices)\n        # Return the indices as tensor objects\n        return torch.tensor(latin_indices, dtype=torch.long), torch.tensor(bangla_indices, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.560993Z","iopub.execute_input":"2024-05-17T12:59:31.561326Z","iopub.status.idle":"2024-05-17T12:59:31.570010Z","shell.execute_reply.started":"2024-05-17T12:59:31.561301Z","shell.execute_reply":"2024-05-17T12:59:31.569102Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"# **Defining a function for padding sequences and packing batches**","metadata":{}},{"cell_type":"code","source":"# Define a function for padding sequences and packing batches\n# packet_fn specifies a function to control how batches are created from the individual data items\ndef packet_fn(batch):\n    # Unzip the batch to separate Latin and Bangla indices\n    latin, bangla = zip(*batch)\n#     print(latin, bangla)\n    # Pad the sequences of Latin indices\n    latin_padded = pad_sequence(latin, batch_first=True, padding_value=latin_token_to_index['<pad>'])\n#     print(latin_padded)\n    # Pad the sequences of Bangla indices\n    bangla_padded = pad_sequence(bangla, batch_first=True, padding_value=bangla_token_to_index['<pad>'])\n#     print(bangla_padded)\n    # Return the padded batches\n    return latin_padded, bangla_padded","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.595929Z","iopub.execute_input":"2024-05-17T12:59:31.596243Z","iopub.status.idle":"2024-05-17T12:59:31.602015Z","shell.execute_reply.started":"2024-05-17T12:59:31.596201Z","shell.execute_reply":"2024-05-17T12:59:31.601038Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"# **Load training data into the AksharantarDataset and then creating the train_loader by Dataloader function**","metadata":{}},{"cell_type":"code","source":"# Load training data into the AksharantarDataset\ntrain_dataset = AksharantarDataset(latin_train, bangla_train, latin_token_to_index, bangla_token_to_index)\n# Create a DataLoader to batch and shuffle the dataset\n# packet_fn specifies a function to control how batches are created from the individual data items\ntrain_loader = DataLoader(train_dataset, batch_size = 64, collate_fn=packet_fn, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.659651Z","iopub.execute_input":"2024-05-17T12:59:31.659996Z","iopub.status.idle":"2024-05-17T12:59:31.665476Z","shell.execute_reply.started":"2024-05-17T12:59:31.659959Z","shell.execute_reply":"2024-05-17T12:59:31.664429Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"# **Print an example from the dataset**","metadata":{}},{"cell_type":"code","source":"# Print an example from the dataset\nprint(train_dataset[4000])\n# for i,j in train_loader:\n#     print(i,'\\n\\n\\n',j)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:31.718618Z","iopub.execute_input":"2024-05-17T12:59:31.718992Z","iopub.status.idle":"2024-05-17T12:59:31.725589Z","shell.execute_reply.started":"2024-05-17T12:59:31.718965Z","shell.execute_reply":"2024-05-17T12:59:31.724501Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"(tensor([19, 23,  7, 20,  5,  7, 22, 11, 16]), tensor([ 2, 17, 50, 43, 47, 56, 32, 51, 36,  0]))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n# **A function for calculating word accuracy per batch, ignoring the padding token**","metadata":{}},{"cell_type":"code","source":"# Define a word accuracy function for word-level accuracy\ndef word_accuracy(outputs, targets, ignore_index):\n    # Assuming outputs and targets are batched sequences of token indices\n    # Ignoring <pad> tokens as specified by `ignore_index`\n    correct = 0  # Initialize the count of correct predictions.\n    total = 0  # Initialize the total number of sequences.\n    for out, tar in zip(outputs, targets):  # Iterate over each output and target pair.\n        # Ignoring padding in accuracy calculation\n#         print('out bef pad:',out)  # Uncomment to print the output before removing padding.\n#         print('tar:',tar)  # Uncomment to print the target.\n        out = out[out != ignore_index]  # Remove padding tokens from the output.\n        tar = tar[tar != ignore_index]  # Remove padding tokens from the target.\n        ignore_index_eos = 0  # Define an ignore index for end of sequence.\n        out = out[out != ignore_index_eos]  # Remove end of sequence tokens from the output.\n        tar = tar[tar != ignore_index_eos]  # Remove end of sequence tokens from the target.\n#         print('out aft pad:',out)  # Uncomment to print the output after removing padding.\n#         print('tar:',tar)  # Uncomment to print the target after removing padding.\n        if torch.equal(out, tar):  # Check if the processed output and target are identical.\n            correct += 1  # Increment the correct count.\n#             print('correct:',correct)  # Uncomment to print the correct count.\n        total += 1  # Increment the total count.\n#         print('total:',total)  # Uncomment to print the total count.\n    return correct / total if total > 0 else 0  # Calculate and return the accuracy.\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:32.740721Z","iopub.execute_input":"2024-05-17T12:59:32.741110Z","iopub.status.idle":"2024-05-17T12:59:32.749221Z","shell.execute_reply.started":"2024-05-17T12:59:32.741078Z","shell.execute_reply":"2024-05-17T12:59:32.748135Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"markdown","source":"\n\n# **Defining the Training function**","metadata":{}},{"cell_type":"code","source":"def train(model, iterator, optimizer, criterion, clip, device, ignore_index):\n    # Set the model to training mode\n    model.train()\n    # Initialize epoch loss and accuracy\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    # Iterate through the data iterator\n    for source, target in iterator:\n        # Move source and target tensors to the specified device\n        source = source.to(device)\n        target = target.to(device)\n        \n        # Zero the gradients\n        optimizer.zero_grad()\n        # Forward pass: compute model predictions\n        output = model(source, target)\n        \n        output_dim = output.shape[-1]\n        # Slice the output and target tensors to remove <sos> token and maintain sequence structure\n        output = output[:, 1:, :]\n        target = target[:, 1:]\n        \n        # Flatten all dimensions except for the batch dimension for loss calculation\n        output_flat = output.reshape(-1, output_dim)\n        target_flat = target.reshape(-1)\n        \n        # Compute the loss\n        loss = criterion(output_flat, target_flat)\n        # Calculate word-by-word accuracy\n        acc = word_accuracy(output.argmax(dim=2), target, ignore_index)\n        \n        # Backpropagation\n        loss.backward()\n        # Clip gradients to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        # Update model parameters\n        optimizer.step()\n        \n        # Accumulate epoch loss and accuracy\n        epoch_loss += loss.item()\n        epoch_acc += acc\n    \n    # Return average epoch loss and accuracy\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:33.432440Z","iopub.execute_input":"2024-05-17T12:59:33.433532Z","iopub.status.idle":"2024-05-17T12:59:33.443999Z","shell.execute_reply.started":"2024-05-17T12:59:33.433490Z","shell.execute_reply":"2024-05-17T12:59:33.442946Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"# **Defining the Evaluation function**","metadata":{"execution":{"iopub.status.busy":"2024-05-02T03:12:54.052339Z","iopub.execute_input":"2024-05-02T03:12:54.053023Z","iopub.status.idle":"2024-05-02T03:12:54.056815Z","shell.execute_reply.started":"2024-05-02T03:12:54.052993Z","shell.execute_reply":"2024-05-02T03:12:54.055862Z"}}},{"cell_type":"code","source":"def evaluate(model, iterator, criterion, device, ignore_index):\n    # Set the model to evaluation mode\n    model.eval()\n    # Initialize epoch loss and accuracy\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    # Iterate through the data iterator\n    with torch.no_grad():\n        for source, target in iterator:\n            # Move source and target tensors to the specified device\n            source = source.to(device)\n            target = target.to(device)\n            \n            # Forward pass: compute model predictions without teacher forcing\n            output = model(source, target, 0)\n            output_dim = output.shape[-1]\n            # Slice the output and target tensors to remove <sos> token and maintain sequence structure\n            output = output[:, 1:, :]\n            target = target[:, 1:]\n            \n            # Flatten all dimensions except for the batch dimension for loss calculation\n            output_flat = output.reshape(-1, output_dim)\n            target_flat = target.reshape(-1)\n            \n            # Compute the loss\n            loss = criterion(output_flat, target_flat)\n            # Calculate word-by-word accuracy\n            acc = word_accuracy(output.argmax(dim=2), target, ignore_index)\n            \n            # Accumulate epoch loss and accuracy\n            epoch_loss += loss.item()\n            epoch_acc += acc\n            \n    # Return average epoch loss and accuracy\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:33.973528Z","iopub.execute_input":"2024-05-17T12:59:33.974335Z","iopub.status.idle":"2024-05-17T12:59:33.985281Z","shell.execute_reply.started":"2024-05-17T12:59:33.974300Z","shell.execute_reply":"2024-05-17T12:59:33.983901Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"markdown","source":"# **Load validation data into the AksharantarDataset and then creating the valid_loader by Dataloader function**","metadata":{}},{"cell_type":"code","source":"# Load validation data by reading a CSV file\nlatin_valid, bangla_valid = load_data('/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_valid.csv')\n\n# Create a validation dataset using the AksharantarDataset class.\nvalid_dataset = AksharantarDataset(latin_valid, bangla_valid, latin_token_to_index, bangla_token_to_index)\n\n# Create a DataLoader to batch and shuffle the dataset\n# 'collate_fn=packet_fn' specifies a function to control how batches are created from the individual data items.\n# 'shuffle=True' ensures that the data is shuffled at every epoch which helps to reduce model overfitting\nvalid_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=packet_fn, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:58:58.547679Z","iopub.execute_input":"2024-05-17T12:58:58.547994Z","iopub.status.idle":"2024-05-17T12:58:58.568027Z","shell.execute_reply.started":"2024-05-17T12:58:58.547968Z","shell.execute_reply":"2024-05-17T12:58:58.566960Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"# **The training process for specified number of epochs**","metadata":{}},{"cell_type":"code","source":"# -embed_size-64-layers_enc-3-layers_dec-3-hid_size-512-cell_type-lstm-bidirectional-True-dropout-0.2\n# Define the dimensions and configurations for the encoder and decoder\nINPUT_DIM = 100\nOUTPUT_DIM = 100\nENC_EMB_DIM = 64\nDEC_EMB_DIM = 64\nHID_DIM = 512\nENC_LAYERS = 3\nDEC_LAYERS = 3\nENC_RNN_CELL = 'lstm'\nDEC_RNN_CELL = 'lstm'\n\n# Initialize the encoder with the specified parameters\nencoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL, dropout=0.2, bidirectional=True)\n# Initialize the decoder with the specified parameters, using the number of encoder layers\ndecoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout=0.2, bidirectional=True)\n# Determine the device for model training (CPU or GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n# Initialize the sequence-to-sequence model with the encoder and decoder\nmodel = Seq_to_Seq(encoder, decoder).to(device)\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:38.298537Z","iopub.execute_input":"2024-05-17T12:59:38.299506Z","iopub.status.idle":"2024-05-17T12:59:38.916507Z","shell.execute_reply.started":"2024-05-17T12:59:38.299465Z","shell.execute_reply":"2024-05-17T12:59:38.915436Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 1536, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=1536, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting the number of epochs the training process should run\nNUM_EPOCHS = 10\n# Set the maximum norm of the gradients to 1 to prevent exploding gradients\nCLIP = 1\n# Initialize the optimizer, Adam\noptimizer = torch.optim.Adam(model.parameters())\n# Create Adam optimizer with default parameters\noptimizer = torch.optim.Adam(model.parameters())\n\n\n# Padding token index should be ignored in loss calculation\nignore_index = bangla_token_to_index['<pad>']\n# Define the loss function with 'ignore_index' to avoid affecting loss calculation with padding tokens\ncriterion = nn.CrossEntropyLoss(ignore_index=ignore_index).to(device)\n\n# Start the training process for the defined number of epochs\nfor epoch in range(NUM_EPOCHS):\n    # Doing training on the train dataset and return average loss and accuracy\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n    # Evaluating the model on the validation dataset and return average loss and accuracy\n    val_loss, val_accuracy = evaluate(model, valid_loader, criterion, device, ignore_index)\n    \n    # Print the loss and accuracy for each epoch\n    print(f'Epoch: {epoch+1}')\n    print(f'\\tTrain_Loss: {train_loss:.3f}, Train_Accuracy: {train_accuracy*100:.2f}%')\n    print(f'\\tVal_Loss: {val_loss:.3f},  Val_Accuracy: {val_accuracy*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:59:38.918459Z","iopub.execute_input":"2024-05-17T12:59:38.919045Z","iopub.status.idle":"2024-05-17T12:59:45.220441Z","shell.execute_reply.started":"2024-05-17T12:59:38.919010Z","shell.execute_reply":"2024-05-17T12:59:45.219038Z"},"trusted":true},"execution_count":152,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[152], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Start the training process for the defined number of epochs\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Doing training on the train dataset and return average loss and accuracy\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Evaluating the model on the validation dataset and return average loss and accuracy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader, criterion, device, ignore_index)\n","Cell \u001b[0;32mIn[149], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, device, ignore_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m acc \u001b[38;5;241m=\u001b[39m word_accuracy(output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), target, ignore_index)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Clip gradients to prevent exploding gradients\u001b[39;00m\n\u001b[1;32m     36\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# **Load the Test data into the AksharantarDataset and then creating the test_loader by Dataloader function**","metadata":{}},{"cell_type":"code","source":"# Load the test data from the specified CSV file location\nlatin_test, bangla_test = load_data('/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_test.csv')\n\n# Create test_dataset using the AksharantarDataset class, initializing it with test data\n# and corresponding token-to-index mappings for both Latin and Bangla scripts\ntest_dataset = AksharantarDataset(latin_test, bangla_test, latin_token_to_index, bangla_token_to_index)\n\n# A DataLoader for the test dataset. Here, the batch size is set to 1, indicates\n# that the model will process one item at a time. This is for testing to make\n# detailed predictions per sample without batching effects.\ntest_loader = DataLoader(test_dataset, batch_size=32, collate_fn=packet_fn, shuffle=False)\n# print(test_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T06:25:56.947504Z","iopub.execute_input":"2024-05-17T06:25:56.948415Z","iopub.status.idle":"2024-05-17T06:25:56.980419Z","shell.execute_reply.started":"2024-05-17T06:25:56.948381Z","shell.execute_reply":"2024-05-17T06:25:56.979535Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"\n\n# **A function to convert an array of indices back into a string, excluding any indices corresponding to special tokens like padding, start, or end of sequence tokens, which should not appear in the final output string**","metadata":{}},{"cell_type":"code","source":"def decode_indices(indices, index_to_token):\n    # Filter out indices for padding, start-of-sequence, and end-of-sequence tokens to ensure only valid character indices are decoded\n    valid_indices = [index for index in indices if index in index_to_token and index not in (bangla_token_to_index['<pad>'], bangla_token_to_index['<sos>'], bangla_token_to_index['<eos>'])]\n    # Convert each index to its corresponding character and join them to form the decoded string\n    return ''.join([index_to_token[index] for index in valid_indices])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T06:26:22.232733Z","iopub.execute_input":"2024-05-17T06:26:22.233119Z","iopub.status.idle":"2024-05-17T06:26:22.239301Z","shell.execute_reply.started":"2024-05-17T06:26:22.233091Z","shell.execute_reply":"2024-05-17T06:26:22.238243Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# **Creating the prediction function to generate outputs for all samples in the test_loader**","metadata":{}},{"cell_type":"code","source":"def predict(model, iterator, device):\n    # Set the model to evaluation mode to disable dropout or batch normalization effects during inference\n    model.eval()\n    predictions = []\n    # Disables gradient calculations for performance improvement since they are not needed in inference\n    with torch.no_grad():\n        for source, target in iterator:\n            # Ensure the source and target tensors are on the correct device (GPU or CPU)\n            source = source.to(device)\n            target = target.to(device)\n            # Obtain model output without teacher forcing (i.e., the model relies entirely on its predictions)\n            output = model(source, target, 0)\n            # Get the index with the highest probability from output predictions\n            output = output.argmax(2)\n            # Convert tensors to CPU numpy arrays for easier manipulation and extraction\n            source = source.cpu().numpy()\n            output = output.cpu().numpy()\n            target = target.cpu().numpy()\n            # Store the tuple of source and decoded output predictions\n            predictions.append((source, target, output))\n    # Return all predictions made over the iterator\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-05-17T06:26:23.231376Z","iopub.execute_input":"2024-05-17T06:26:23.232313Z","iopub.status.idle":"2024-05-17T06:26:23.239461Z","shell.execute_reply.started":"2024-05-17T06:26:23.232279Z","shell.execute_reply":"2024-05-17T06:26:23.238407Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# **Creating dictionaries to map indices back to its corresponding characters**","metadata":{}},{"cell_type":"code","source":"# Create dictionaries to map indices back to characters, observing the interpretation of prediction outputs\nlatin_index_to_token = {index: char for char, index in latin_token_to_index.items()}\nbangla_index_to_token = {index: char for char, index in bangla_token_to_index.items()}\n# print(latin_index_to_token)\n# print(bangla_index_to_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T06:26:25.038010Z","iopub.execute_input":"2024-05-17T06:26:25.038794Z","iopub.status.idle":"2024-05-17T06:26:25.043998Z","shell.execute_reply.started":"2024-05-17T06:26:25.038763Z","shell.execute_reply":"2024-05-17T06:26:25.042887Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# **Displaying results: Each input text from the test dataset and its corresponding predicted output text are printed. This helps in visually assessing the accuracy and quality of the transliterations produced by the model**","metadata":{}},{"cell_type":"code","source":"# Taking the prediction function to generate outputs for all samples in the test_loader\ntest_predictions = predict(model, test_loader, device)\n# print(len(test_predictions[0]))\n# Loop through the list of tuples containing source and output indices from the test predictions\nfor source_indices, target_indices, output_indices in test_predictions:\n    # Iterate through each example in the batch. This is necessary as batches may contain multiple examples\n    for i in range(source_indices.shape[0]):\n        # Decode the source indices to their corresponding text using the mapping dictionary for Latin script\n        input_text = decode_indices(source_indices[i], latin_index_to_token)\n        \n        target_text = decode_indices(target_indices[i], bangla_index_to_token)\n\n        # Decode the output indices to their corresponding text using the mapping dictionary for Bangla script\n        predicted_text = decode_indices(output_indices[i], bangla_index_to_token)\n        # Print the original input text and its corresponding predicted transliteration\n        print(f'Input Text: {input_text} -> Actual Text: {target_text} -> Predicted Text: {predicted_text}')\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T13:33:22.223237Z","iopub.execute_input":"2024-05-16T13:33:22.223631Z","iopub.status.idle":"2024-05-16T13:33:25.994579Z","shell.execute_reply.started":"2024-05-16T13:33:22.223601Z","shell.execute_reply":"2024-05-16T13:33:25.993577Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **CSV File creation**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Create lists to store the data\ninput_texts = []\nactual_texts = []\npredicted_texts = []\ntest_predictions = predict(model, test_loader, device)\n\n# Loop through the list of tuples containing source and output indices from the test predictions\nfor source_indices, target_indices, output_indices in test_predictions:\n    # Iterate through each example in the batch. This is necessary as batches may contain multiple examples\n    for i in range(source_indices.shape[0]):\n        # Decode the source indices to their corresponding text using the mapping dictionary for Latin script\n        input_text = decode_indices(source_indices[i], latin_index_to_token)\n        target_text = decode_indices(target_indices[i], bangla_index_to_token)\n        # Decode the output indices to their corresponding text using the mapping dictionary for Bangla script\n        predicted_text = decode_indices(output_indices[i], bangla_index_to_token)\n        # Append the texts to the lists\n        input_texts.append(input_text)\n        actual_texts.append(target_text)\n        predicted_texts.append(predicted_text)\n\n# Create a DataFrame from the lists\ndf = pd.DataFrame({\n    'Input Text': input_texts,\n    'Actual Text': actual_texts,\n    'Predicted Text': predicted_texts\n})\n\n# Save the DataFrame to a CSV file\ndf.to_csv('predictions_without_attn.csv', index=False, encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T06:26:33.341444Z","iopub.execute_input":"2024-05-17T06:26:33.341820Z","iopub.status.idle":"2024-05-17T06:26:37.456883Z","shell.execute_reply.started":"2024-05-17T06:26:33.341793Z","shell.execute_reply":"2024-05-17T06:26:37.455806Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# **Wandb Setup**","metadata":{}},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random\n\n# key = input('Enter your API:')\nwandb.login(key='25c2257eaf6c22aa056893db14da4ee2bf0a531a')  #25c2257eaf6c22aa056893db14da4ee2bf0a531a","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:28:42.698221Z","iopub.execute_input":"2024-05-17T12:28:42.699042Z","iopub.status.idle":"2024-05-17T12:28:45.775590Z","shell.execute_reply.started":"2024-05-17T12:28:42.699011Z","shell.execute_reply":"2024-05-17T12:28:45.774594Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# **For training and evaluating model on the training and validation dataset wandb setup**","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep all final new lr 5',\n    'metric': {\n        'name': 'Val_Accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'input_embed_size': {\n            'values': [16,32,64,256,512]\n        },\n        'num_enc_layers':{\n            'values': [1,2,3]\n        },\n        'num_dec_layers':{\n            'values': [1,2,3]\n        },\n        'hid_layer_size': {\n            'values': [16,32,64,256,512]\n        },\n        'cell_type': {\n            'values': ['lstm']\n        },\n        'bidirectional':{\n            'values': [True, False]\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n        'new_learning_rate':{\n            'values': [0.001,0.01,0.1]\n        }\n#       'beam search in decoder with different beam sizes': \n    }\n}\n\nsweep_id = wandb.sweep(sweep = sweep_config, project=\"Deep_Learning_A3\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:28:49.126475Z","iopub.execute_input":"2024-05-17T12:28:49.127350Z","iopub.status.idle":"2024-05-17T12:28:49.397114Z","shell.execute_reply.started":"2024-05-17T12:28:49.127318Z","shell.execute_reply":"2024-05-17T12:28:49.396175Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Create sweep with ID: qza57kfp\nSweep URL: https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/qza57kfp\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\ndef main():\n    # Initialize a new wandb run\n    with wandb.init() as run:\n        # Construct run name from configuration\n        run_name = \"-embed_size-\"+str(wandb.config.input_embed_size)+\"-layers_enc-\"+str(wandb.config.num_enc_layers)+\"-layers_dec-\"+str(wandb.config.num_dec_layers)+\"-hid_size-\"+str(wandb.config.hid_layer_size)+\"-cell_type-\"+wandb.config.cell_type+\"-bidirectional-\"+str(wandb.config.bidirectional)+\"-dropout-\"+str(wandb.config.dropout)+\"-lr-\"+str(wandb.config.new_learning_rate)\n        wandb.run.name = run_name\n\n        # Constants defining the dimensions of the input and output character sets\n        INPUT_DIM = 100  # size of the Latin character set\n        OUTPUT_DIM = 100  # size of the Bangla character set\n\n        # Constants defining the dimensions of the embeddings for encoder and decoder\n        ENC_EMB_DIM = wandb.config.input_embed_size  # Encoder embedding dimension\n        DEC_EMB_DIM = wandb.config.input_embed_size  # Decoder embedding dimension\n\n        # Constants defining the dimension of the hidden layers for encoder and decoder\n        HID_DIM = wandb.config.hid_layer_size  # Hidden dimension size\n\n        # Constants defining the number of layers for encoder and decoder\n        ENC_LAYERS = wandb.config.num_enc_layers  # Number of layers in the encoder\n        DEC_LAYERS = wandb.config.num_dec_layers  # Number of layers in the decoder\n        \n\n        # Constants defining the type of RNN cell to use for encoder and decoder\n        ENC_RNN_CELL = wandb.config.cell_type  # RNN cell type for the encoder\n        DEC_RNN_CELL = wandb.config.cell_type  # RNN cell type for the decoder\n\n        # Instantiate the encoder with specified configurations\n        encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL, dropout = wandb.config.dropout, bidirectional = wandb.config.bidirectional)\n        # Instantiate the decoder with specified configurations\n        decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout = wandb.config.dropout, bidirectional = wandb.config.bidirectional)\n\n        # Determine the computing device (CUDA if available, otherwise CPU)\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        # Print the device will be used\n        print(f\"Using device: {device}\")\n\n        # Instantiate the Seq_to_Seq model and move it to the chosen computing device\n        model = Seq_to_Seq(encoder, decoder).to(device)\n        print(model)\n        \n        \n        # Setting the number of epochs the training process should run\n        NUM_EPOCHS = 7\n        # Set the maximum norm of the gradients to 1 to prevent exploding gradients\n        CLIP = 1\n        # Initialize the optimizer, Adam\n        optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.new_learning_rate)  # Set the learning rate to 0.001\n\n\n        # Padding token index should be ignored in loss calculation\n        ignore_index = bangla_token_to_index['<pad>']\n        # Define the loss function with 'ignore_index' to avoid affecting loss calculation with padding tokens\n        criterion = nn.CrossEntropyLoss(ignore_index=ignore_index).to(device)\n\n        # Start the training process for the defined number of epochs\n        for epoch in range(NUM_EPOCHS):\n            # Doing training on the train dataset and return average loss and accuracy\n            train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n            # Evaluating the model on the validation dataset and return average loss and accuracy\n            val_loss, val_accuracy = evaluate(model, valid_loader, criterion, device, ignore_index)\n\n            # Print the loss and accuracy for each epoch\n            print(f'Epoch: {epoch+1}')\n            print(f'\\tTrain_Loss: {train_loss:.3f}, Train_Accuracy: {train_accuracy*100:.2f}%')\n            print(f'\\tVal_Loss: {val_loss:.3f},  Val_Accuracy: {val_accuracy*100:.2f}%')\n            wandb.log({\"train_accuracy\": train_accuracy * 100, \"training_loss\": train_loss})\n            wandb.log({\"Val_Accuracy\": val_accuracy * 100, \"Val_Loss\": val_loss})\n\n\nwandb.agent(sweep_id, function=main, count=50)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T05:52:13.938345Z","iopub.execute_input":"2024-05-16T05:52:13.939242Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ucipipva with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_055216-ucipipva</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ucipipva' target=\"_blank\">youthful-sweep-1</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ucipipva' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ucipipva</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 256, num_layers=2, batch_first=True, dropout=0.3)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 256, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=256, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.972, Train_Accuracy: 0.00%\n\tVal_Loss: 2.867,  Val_Accuracy: 0.07%\nEpoch: 2\n\tTrain_Loss: 2.372, Train_Accuracy: 0.04%\n\tVal_Loss: 2.085,  Val_Accuracy: 1.12%\nEpoch: 3\n\tTrain_Loss: 1.790, Train_Accuracy: 1.00%\n\tVal_Loss: 1.655,  Val_Accuracy: 7.45%\nEpoch: 4\n\tTrain_Loss: 1.444, Train_Accuracy: 2.82%\n\tVal_Loss: 1.458,  Val_Accuracy: 12.21%\nEpoch: 5\n\tTrain_Loss: 1.227, Train_Accuracy: 5.19%\n\tVal_Loss: 1.373,  Val_Accuracy: 12.28%\nEpoch: 6\n\tTrain_Loss: 1.088, Train_Accuracy: 7.38%\n\tVal_Loss: 1.313,  Val_Accuracy: 16.55%\nEpoch: 7\n\tTrain_Loss: 0.986, Train_Accuracy: 9.63%\n\tVal_Loss: 1.274,  Val_Accuracy: 20.14%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▄▅▅▇█</td></tr><tr><td>Val_Loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▅▆█</td></tr><tr><td>training_loss</td><td>█▆▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>20.1416</td></tr><tr><td>Val_Loss</td><td>1.27364</td></tr><tr><td>train_accuracy</td><td>9.63086</td></tr><tr><td>training_loss</td><td>0.986</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">youthful-sweep-1</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ucipipva' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ucipipva</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_055216-ucipipva/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6y2i95e4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_055710-6y2i95e4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/6y2i95e4' target=\"_blank\">youthful-sweep-2</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/6y2i95e4' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/6y2i95e4</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.440, Train_Accuracy: 0.43%\n\tVal_Loss: 1.823,  Val_Accuracy: 6.05%\nEpoch: 2\n\tTrain_Loss: 1.201, Train_Accuracy: 9.26%\n\tVal_Loss: 1.351,  Val_Accuracy: 17.65%\nEpoch: 3\n\tTrain_Loss: 0.866, Train_Accuracy: 15.92%\n\tVal_Loss: 1.263,  Val_Accuracy: 20.24%\nEpoch: 4\n\tTrain_Loss: 0.729, Train_Accuracy: 19.67%\n\tVal_Loss: 1.192,  Val_Accuracy: 23.41%\nEpoch: 5\n\tTrain_Loss: 0.626, Train_Accuracy: 23.88%\n\tVal_Loss: 1.170,  Val_Accuracy: 28.83%\nEpoch: 6\n\tTrain_Loss: 0.562, Train_Accuracy: 26.22%\n\tVal_Loss: 1.101,  Val_Accuracy: 31.86%\nEpoch: 7\n\tTrain_Loss: 0.503, Train_Accuracy: 28.47%\n\tVal_Loss: 1.108,  Val_Accuracy: 26.22%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded\\r'), FloatProgress(value=0.07226785899968806, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▄▅▆▇█▆</td></tr><tr><td>Val_Loss</td><td>█▃▃▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇▇█</td></tr><tr><td>training_loss</td><td>█▄▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>26.2207</td></tr><tr><td>Val_Loss</td><td>1.10827</td></tr><tr><td>train_accuracy</td><td>28.47266</td></tr><tr><td>training_loss</td><td>0.50294</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">youthful-sweep-2</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/6y2i95e4' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/6y2i95e4</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_055710-6y2i95e4/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zxpvi8o6 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_060325-zxpvi8o6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zxpvi8o6' target=\"_blank\">ethereal-sweep-3</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zxpvi8o6' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zxpvi8o6</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 128, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 768, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=768, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.141, Train_Accuracy: 0.72%\n\tVal_Loss: 1.655,  Val_Accuracy: 5.66%\nEpoch: 2\n\tTrain_Loss: 1.379, Train_Accuracy: 3.89%\n\tVal_Loss: 1.529,  Val_Accuracy: 8.50%\nEpoch: 3\n\tTrain_Loss: 1.220, Train_Accuracy: 5.41%\n\tVal_Loss: 1.463,  Val_Accuracy: 12.50%\nEpoch: 4\n\tTrain_Loss: 1.131, Train_Accuracy: 6.84%\n\tVal_Loss: 1.387,  Val_Accuracy: 12.50%\nEpoch: 5\n\tTrain_Loss: 1.086, Train_Accuracy: 7.17%\n\tVal_Loss: 1.362,  Val_Accuracy: 15.21%\nEpoch: 6\n\tTrain_Loss: 1.059, Train_Accuracy: 8.14%\n\tVal_Loss: 1.363,  Val_Accuracy: 16.31%\nEpoch: 7\n\tTrain_Loss: 1.032, Train_Accuracy: 8.04%\n\tVal_Loss: 1.370,  Val_Accuracy: 15.06%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▃▅▅▇█▇</td></tr><tr><td>Val_Loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▇▇██</td></tr><tr><td>training_loss</td><td>█▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>15.06348</td></tr><tr><td>Val_Loss</td><td>1.36958</td></tr><tr><td>train_accuracy</td><td>8.03516</td></tr><tr><td>training_loss</td><td>1.03156</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ethereal-sweep-3</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zxpvi8o6' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zxpvi8o6</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_060325-zxpvi8o6/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hnz3vy39 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_060905-hnz3vy39</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hnz3vy39' target=\"_blank\">lucky-sweep-4</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hnz3vy39' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hnz3vy39</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 1536, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=1536, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.284, Train_Accuracy: 0.00%\n\tVal_Loss: 3.158,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.190, Train_Accuracy: 0.00%\n\tVal_Loss: 3.093,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 3.142, Train_Accuracy: 0.00%\n\tVal_Loss: 3.231,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 3.141, Train_Accuracy: 0.00%\n\tVal_Loss: 3.020,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 3.133, Train_Accuracy: 0.00%\n\tVal_Loss: 3.077,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 3.137, Train_Accuracy: 0.00%\n\tVal_Loss: 3.063,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 3.147, Train_Accuracy: 0.00%\n\tVal_Loss: 3.001,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▄█▂▃▃▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▄▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.00119</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>3.14736</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lucky-sweep-4</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hnz3vy39' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hnz3vy39</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_060905-hnz3vy39/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pvlqb6a6 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_062349-pvlqb6a6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pvlqb6a6' target=\"_blank\">fallen-sweep-5</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pvlqb6a6' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pvlqb6a6</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(32, 32, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(32, 192, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=192, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.024, Train_Accuracy: 0.00%\n\tVal_Loss: 2.931,  Val_Accuracy: 0.02%\nEpoch: 2\n\tTrain_Loss: 2.628, Train_Accuracy: 0.00%\n\tVal_Loss: 2.436,  Val_Accuracy: 0.15%\nEpoch: 3\n\tTrain_Loss: 2.152, Train_Accuracy: 0.14%\n\tVal_Loss: 1.988,  Val_Accuracy: 2.12%\nEpoch: 4\n\tTrain_Loss: 1.791, Train_Accuracy: 0.85%\n\tVal_Loss: 1.766,  Val_Accuracy: 5.71%\nEpoch: 5\n\tTrain_Loss: 1.567, Train_Accuracy: 1.95%\n\tVal_Loss: 1.628,  Val_Accuracy: 9.18%\nEpoch: 6\n\tTrain_Loss: 1.421, Train_Accuracy: 3.43%\n\tVal_Loss: 1.470,  Val_Accuracy: 11.13%\nEpoch: 7\n\tTrain_Loss: 1.308, Train_Accuracy: 4.18%\n\tVal_Loss: 1.470,  Val_Accuracy: 13.06%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▂▄▆▇█</td></tr><tr><td>Val_Loss</td><td>█▆▃▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▄▇█</td></tr><tr><td>training_loss</td><td>█▆▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>13.06152</td></tr><tr><td>Val_Loss</td><td>1.46997</td></tr><tr><td>train_accuracy</td><td>4.18164</td></tr><tr><td>training_loss</td><td>1.30768</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fallen-sweep-5</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pvlqb6a6' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/pvlqb6a6</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_062349-pvlqb6a6/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cn29cvbs with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_063024-cn29cvbs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cn29cvbs' target=\"_blank\">whole-sweep-6</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cn29cvbs' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cn29cvbs</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(32, 8, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(32, 32, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.233, Train_Accuracy: 0.00%\n\tVal_Loss: 2.986,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.869, Train_Accuracy: 0.00%\n\tVal_Loss: 2.874,  Val_Accuracy: 0.02%\nEpoch: 3\n\tTrain_Loss: 2.718, Train_Accuracy: 0.01%\n\tVal_Loss: 2.675,  Val_Accuracy: 0.12%\nEpoch: 4\n\tTrain_Loss: 2.577, Train_Accuracy: 0.01%\n\tVal_Loss: 2.561,  Val_Accuracy: 0.24%\nEpoch: 5\n\tTrain_Loss: 2.473, Train_Accuracy: 0.03%\n\tVal_Loss: 2.456,  Val_Accuracy: 0.27%\nEpoch: 6\n\tTrain_Loss: 2.387, Train_Accuracy: 0.05%\n\tVal_Loss: 2.384,  Val_Accuracy: 0.34%\nEpoch: 7\n\tTrain_Loss: 2.330, Train_Accuracy: 0.07%\n\tVal_Loss: 2.306,  Val_Accuracy: 0.66%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.07139555190302532, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▂▄▄▅█</td></tr><tr><td>Val_Loss</td><td>█▇▅▄▃▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▂▃▆█</td></tr><tr><td>training_loss</td><td>█▅▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.65918</td></tr><tr><td>Val_Loss</td><td>2.30618</td></tr><tr><td>train_accuracy</td><td>0.07227</td></tr><tr><td>training_loss</td><td>2.33035</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">whole-sweep-6</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cn29cvbs' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cn29cvbs</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_063024-cn29cvbs/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fyl5yvh8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_063513-fyl5yvh8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/fyl5yvh8' target=\"_blank\">ruby-sweep-7</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/fyl5yvh8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/fyl5yvh8</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, batch_first=True)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.261, Train_Accuracy: 0.00%\n\tVal_Loss: 3.154,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.153, Train_Accuracy: 0.00%\n\tVal_Loss: 3.274,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 3.193, Train_Accuracy: 0.00%\n\tVal_Loss: 3.340,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 3.190, Train_Accuracy: 0.00%\n\tVal_Loss: 3.194,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 3.259, Train_Accuracy: 0.00%\n\tVal_Loss: 3.361,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 3.240, Train_Accuracy: 0.00%\n\tVal_Loss: 3.230,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 3.232, Train_Accuracy: 0.00%\n\tVal_Loss: 3.193,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅▇▂█▄▂</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▁▄▃█▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.19278</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>3.23167</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ruby-sweep-7</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/fyl5yvh8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/fyl5yvh8</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_063513-fyl5yvh8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 127nxe86 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_064011-127nxe86</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/127nxe86' target=\"_blank\">floral-sweep-8</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/127nxe86' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/127nxe86</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 512, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.957, Train_Accuracy: 0.00%\n\tVal_Loss: 2.786,  Val_Accuracy: 0.02%\nEpoch: 2\n\tTrain_Loss: 2.173, Train_Accuracy: 0.26%\n\tVal_Loss: 1.891,  Val_Accuracy: 3.20%\nEpoch: 3\n\tTrain_Loss: 1.501, Train_Accuracy: 3.86%\n\tVal_Loss: 1.524,  Val_Accuracy: 10.84%\nEpoch: 4\n\tTrain_Loss: 1.154, Train_Accuracy: 8.47%\n\tVal_Loss: 1.393,  Val_Accuracy: 16.14%\nEpoch: 5\n\tTrain_Loss: 0.971, Train_Accuracy: 10.87%\n\tVal_Loss: 1.274,  Val_Accuracy: 16.94%\nEpoch: 6\n\tTrain_Loss: 0.842, Train_Accuracy: 13.10%\n\tVal_Loss: 1.236,  Val_Accuracy: 18.87%\nEpoch: 7\n\tTrain_Loss: 0.742, Train_Accuracy: 15.87%\n\tVal_Loss: 1.224,  Val_Accuracy: 22.36%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▂▄▆▆▇█</td></tr><tr><td>Val_Loss</td><td>█▄▂▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▃▅▆▇█</td></tr><tr><td>training_loss</td><td>█▆▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>22.36328</td></tr><tr><td>Val_Loss</td><td>1.22428</td></tr><tr><td>train_accuracy</td><td>15.86719</td></tr><tr><td>training_loss</td><td>0.74159</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">floral-sweep-8</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/127nxe86' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/127nxe86</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_064011-127nxe86/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2rgssalt with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_064546-2rgssalt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/2rgssalt' target=\"_blank\">swept-sweep-9</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/2rgssalt' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/2rgssalt</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 512, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 3\n\tTrain_Loss: 2.821, Train_Accuracy: 0.00%\n\tVal_Loss: 2.944,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.766, Train_Accuracy: 0.00%\n\tVal_Loss: 2.916,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.721, Train_Accuracy: 0.00%\n\tVal_Loss: 2.876,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.681, Train_Accuracy: 0.00%\n\tVal_Loss: 2.870,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.653, Train_Accuracy: 0.00%\n\tVal_Loss: 2.808,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▆▅▃▃▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▆▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>2.80793</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.65335</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">swept-sweep-9</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/2rgssalt' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/2rgssalt</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_064546-2rgssalt/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlrn2y4u with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_065131-jlrn2y4u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/jlrn2y4u' target=\"_blank\">revived-sweep-10</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/jlrn2y4u' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/jlrn2y4u</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.635, Train_Accuracy: 0.03%\n\tVal_Loss: 2.322,  Val_Accuracy: 0.51%\nEpoch: 2\n\tTrain_Loss: 2.128, Train_Accuracy: 0.24%\n\tVal_Loss: 2.151,  Val_Accuracy: 1.37%\nEpoch: 3\n\tTrain_Loss: 1.984, Train_Accuracy: 0.50%\n\tVal_Loss: 1.998,  Val_Accuracy: 2.00%\nEpoch: 4\n\tTrain_Loss: 1.877, Train_Accuracy: 0.83%\n\tVal_Loss: 1.951,  Val_Accuracy: 3.39%\nEpoch: 5\n\tTrain_Loss: 1.820, Train_Accuracy: 1.06%\n\tVal_Loss: 1.894,  Val_Accuracy: 3.20%\nEpoch: 6\n\tTrain_Loss: 1.774, Train_Accuracy: 1.42%\n\tVal_Loss: 1.864,  Val_Accuracy: 3.61%\nEpoch: 7\n\tTrain_Loss: 1.753, Train_Accuracy: 1.48%\n\tVal_Loss: 1.821,  Val_Accuracy: 4.20%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▃▄▆▆▇█</td></tr><tr><td>Val_Loss</td><td>█▆▃▃▂▂▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▅▆██</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>4.19922</td></tr><tr><td>Val_Loss</td><td>1.82083</td></tr><tr><td>train_accuracy</td><td>1.48047</td></tr><tr><td>training_loss</td><td>1.75254</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">revived-sweep-10</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/jlrn2y4u' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/jlrn2y4u</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_065131-jlrn2y4u/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9fsl9gx1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_065700-9fsl9gx1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/9fsl9gx1' target=\"_blank\">honest-sweep-11</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/9fsl9gx1' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/9fsl9gx1</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(256, 64, num_layers=3, batch_first=True, dropout=0.3)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(256, 64, batch_first=True)\n    (fc): Linear(in_features=64, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.966, Train_Accuracy: 0.00%\n\tVal_Loss: 3.084,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.897, Train_Accuracy: 0.00%\n\tVal_Loss: 3.063,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.859, Train_Accuracy: 0.00%\n\tVal_Loss: 3.028,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.848, Train_Accuracy: 0.00%\n\tVal_Loss: 3.059,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.836, Train_Accuracy: 0.00%\n\tVal_Loss: 3.033,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.826, Train_Accuracy: 0.00%\n\tVal_Loss: 3.076,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.820, Train_Accuracy: 0.00%\n\tVal_Loss: 3.010,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▆▃▆▃▇▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁█▁</td></tr><tr><td>training_loss</td><td>█▅▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.00976</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.81953</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">honest-sweep-11</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/9fsl9gx1' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/9fsl9gx1</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_065700-9fsl9gx1/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xwgj6yyk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_070131-xwgj6yyk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/xwgj6yyk' target=\"_blank\">peachy-sweep-12</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/xwgj6yyk' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/xwgj6yyk</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 16, num_layers=3, batch_first=True, dropout=0.3)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 16, batch_first=True)\n    (fc): Linear(in_features=16, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.366, Train_Accuracy: 0.00%\n\tVal_Loss: 3.124,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.074, Train_Accuracy: 0.00%\n\tVal_Loss: 3.064,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.987, Train_Accuracy: 0.00%\n\tVal_Loss: 3.017,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.953, Train_Accuracy: 0.00%\n\tVal_Loss: 3.053,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.931, Train_Accuracy: 0.00%\n\tVal_Loss: 3.012,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.916, Train_Accuracy: 0.00%\n\tVal_Loss: 3.023,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.903, Train_Accuracy: 0.00%\n\tVal_Loss: 3.014,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded\\r'), FloatProgress(value=0.0724448845572523, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▄▁▄▁▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▄▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.01378</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.9029</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">peachy-sweep-12</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/xwgj6yyk' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/xwgj6yyk</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_070131-xwgj6yyk/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5z4zpd7y with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_070601-5z4zpd7y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5z4zpd7y' target=\"_blank\">drawn-sweep-13</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5z4zpd7y' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5z4zpd7y</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 8, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 48, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=48, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.953, Train_Accuracy: 0.00%\n\tVal_Loss: 2.776,  Val_Accuracy: 0.05%\nEpoch: 2\n\tTrain_Loss: 2.584, Train_Accuracy: 0.01%\n\tVal_Loss: 2.538,  Val_Accuracy: 0.02%\nEpoch: 3\n\tTrain_Loss: 2.413, Train_Accuracy: 0.02%\n\tVal_Loss: 2.393,  Val_Accuracy: 0.15%\nEpoch: 4\n\tTrain_Loss: 2.328, Train_Accuracy: 0.03%\n\tVal_Loss: 2.332,  Val_Accuracy: 0.27%\nEpoch: 5\n\tTrain_Loss: 2.278, Train_Accuracy: 0.02%\n\tVal_Loss: 2.308,  Val_Accuracy: 0.42%\nEpoch: 6\n\tTrain_Loss: 2.244, Train_Accuracy: 0.04%\n\tVal_Loss: 2.297,  Val_Accuracy: 0.51%\nEpoch: 7\n\tTrain_Loss: 2.221, Train_Accuracy: 0.05%\n\tVal_Loss: 2.246,  Val_Accuracy: 0.37%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▃▅▇█▆</td></tr><tr><td>Val_Loss</td><td>█▅▃▂▂▂▁</td></tr><tr><td>train_accuracy</td><td>▁▂▅▅▅▇█</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.36621</td></tr><tr><td>Val_Loss</td><td>2.24628</td></tr><tr><td>train_accuracy</td><td>0.04688</td></tr><tr><td>training_loss</td><td>2.22128</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">drawn-sweep-13</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5z4zpd7y' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5z4zpd7y</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_070601-5z4zpd7y/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: um3lh8ax with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_071103-um3lh8ax</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/um3lh8ax' target=\"_blank\">jumping-sweep-14</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/um3lh8ax' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/um3lh8ax</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 32, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 32, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.275, Train_Accuracy: 0.00%\n\tVal_Loss: 3.069,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.015, Train_Accuracy: 0.00%\n\tVal_Loss: 3.056,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.936, Train_Accuracy: 0.00%\n\tVal_Loss: 3.015,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.901, Train_Accuracy: 0.00%\n\tVal_Loss: 2.968,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.870, Train_Accuracy: 0.00%\n\tVal_Loss: 2.968,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.836, Train_Accuracy: 0.00%\n\tVal_Loss: 2.895,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.798, Train_Accuracy: 0.00%\n\tVal_Loss: 2.884,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.07163471449185735, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▆▄▄▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>2.88362</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.79808</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jumping-sweep-14</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/um3lh8ax' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/um3lh8ax</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_071103-um3lh8ax/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5nx1gqia with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_071540-5nx1gqia</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5nx1gqia' target=\"_blank\">silver-sweep-15</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5nx1gqia' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5nx1gqia</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(64, 1024, batch_first=True)\n    (fc): Linear(in_features=1024, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.501, Train_Accuracy: 0.00%\n\tVal_Loss: 2.262,  Val_Accuracy: 0.59%\nEpoch: 2\n\tTrain_Loss: 2.031, Train_Accuracy: 0.24%\n\tVal_Loss: 2.041,  Val_Accuracy: 1.64%\nEpoch: 3\n\tTrain_Loss: 1.810, Train_Accuracy: 0.67%\n\tVal_Loss: 1.917,  Val_Accuracy: 2.66%\nEpoch: 4\n\tTrain_Loss: 1.643, Train_Accuracy: 1.18%\n\tVal_Loss: 1.765,  Val_Accuracy: 4.00%\nEpoch: 5\n\tTrain_Loss: 1.531, Train_Accuracy: 1.47%\n\tVal_Loss: 1.745,  Val_Accuracy: 6.27%\nEpoch: 6\n\tTrain_Loss: 1.477, Train_Accuracy: 1.27%\n\tVal_Loss: 1.641,  Val_Accuracy: 6.54%\nEpoch: 7\n\tTrain_Loss: 1.421, Train_Accuracy: 1.44%\n\tVal_Loss: 1.648,  Val_Accuracy: 7.81%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▂▃▄▇▇█</td></tr><tr><td>Val_Loss</td><td>█▆▄▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▄▇█▇█</td></tr><tr><td>training_loss</td><td>█▅▄▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>7.8125</td></tr><tr><td>Val_Loss</td><td>1.64825</td></tr><tr><td>train_accuracy</td><td>1.44336</td></tr><tr><td>training_loss</td><td>1.42079</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silver-sweep-15</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5nx1gqia' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5nx1gqia</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_071540-5nx1gqia/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ihwqu15r with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_072039-ihwqu15r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ihwqu15r' target=\"_blank\">efficient-sweep-16</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ihwqu15r' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ihwqu15r</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(32, 16, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(32, 32, batch_first=True)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.113, Train_Accuracy: 0.00%\n\tVal_Loss: 2.750,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.661, Train_Accuracy: 0.01%\n\tVal_Loss: 2.536,  Val_Accuracy: 0.29%\nEpoch: 3\n\tTrain_Loss: 2.520, Train_Accuracy: 0.03%\n\tVal_Loss: 2.410,  Val_Accuracy: 0.51%\nEpoch: 4\n\tTrain_Loss: 2.420, Train_Accuracy: 0.07%\n\tVal_Loss: 2.313,  Val_Accuracy: 0.78%\nEpoch: 5\n\tTrain_Loss: 2.350, Train_Accuracy: 0.08%\n\tVal_Loss: 2.263,  Val_Accuracy: 1.03%\nEpoch: 6\n\tTrain_Loss: 2.298, Train_Accuracy: 0.14%\n\tVal_Loss: 2.213,  Val_Accuracy: 1.29%\nEpoch: 7\n\tTrain_Loss: 2.254, Train_Accuracy: 0.16%\n\tVal_Loss: 2.177,  Val_Accuracy: 1.54%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▂▃▅▆▇█</td></tr><tr><td>Val_Loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▄▅▇█</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>1.53809</td></tr><tr><td>Val_Loss</td><td>2.17742</td></tr><tr><td>train_accuracy</td><td>0.15625</td></tr><tr><td>training_loss</td><td>2.25369</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">efficient-sweep-16</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ihwqu15r' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ihwqu15r</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_072039-ihwqu15r/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wnr59c0h with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_072508-wnr59c0h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wnr59c0h' target=\"_blank\">exalted-sweep-17</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wnr59c0h' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wnr59c0h</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 8, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 48, batch_first=True)\n    (fc): Linear(in_features=48, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.988, Train_Accuracy: 0.00%\n\tVal_Loss: 2.785,  Val_Accuracy: 0.02%\nEpoch: 2\n\tTrain_Loss: 2.536, Train_Accuracy: 0.01%\n\tVal_Loss: 2.492,  Val_Accuracy: 0.15%\nEpoch: 3\n\tTrain_Loss: 2.352, Train_Accuracy: 0.04%\n\tVal_Loss: 2.324,  Val_Accuracy: 0.42%\nEpoch: 4\n\tTrain_Loss: 2.251, Train_Accuracy: 0.11%\n\tVal_Loss: 2.233,  Val_Accuracy: 0.78%\nEpoch: 5\n\tTrain_Loss: 2.170, Train_Accuracy: 0.17%\n\tVal_Loss: 2.163,  Val_Accuracy: 1.20%\nEpoch: 6\n\tTrain_Loss: 2.097, Train_Accuracy: 0.28%\n\tVal_Loss: 2.086,  Val_Accuracy: 1.81%\nEpoch: 7\n\tTrain_Loss: 2.032, Train_Accuracy: 0.35%\n\tVal_Loss: 2.028,  Val_Accuracy: 2.05%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▂▄▅▇█</td></tr><tr><td>Val_Loss</td><td>█▅▄▃▂▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▅▇█</td></tr><tr><td>training_loss</td><td>█▅▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>2.05078</td></tr><tr><td>Val_Loss</td><td>2.0282</td></tr><tr><td>train_accuracy</td><td>0.3457</td></tr><tr><td>training_loss</td><td>2.0317</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">exalted-sweep-17</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wnr59c0h' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wnr59c0h</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_072508-wnr59c0h/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qdzrspqo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_072947-qdzrspqo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qdzrspqo' target=\"_blank\">desert-sweep-18</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qdzrspqo' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qdzrspqo</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(64, 512, num_layers=3, batch_first=True, dropout=0.3)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(64, 512, batch_first=True)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.182, Train_Accuracy: 0.00%\n\tVal_Loss: 3.274,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.115, Train_Accuracy: 0.00%\n\tVal_Loss: 3.154,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 3.091, Train_Accuracy: 0.00%\n\tVal_Loss: 3.194,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 3.084, Train_Accuracy: 0.00%\n\tVal_Loss: 3.149,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 3.085, Train_Accuracy: 0.00%\n\tVal_Loss: 3.141,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 3.084, Train_Accuracy: 0.00%\n\tVal_Loss: 3.172,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 3.090, Train_Accuracy: 0.00%\n\tVal_Loss: 3.147,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▂▄▁▁▃▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.14683</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>3.09036</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">desert-sweep-18</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qdzrspqo' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qdzrspqo</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_072947-qdzrspqo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1ofys77n with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_073448-1ofys77n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1ofys77n' target=\"_blank\">warm-sweep-19</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1ofys77n' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1ofys77n</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(512, 8, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(512, 48, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=48, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.233, Train_Accuracy: 0.00%\n\tVal_Loss: 3.036,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.960, Train_Accuracy: 0.00%\n\tVal_Loss: 3.035,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.892, Train_Accuracy: 0.00%\n\tVal_Loss: 2.947,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.828, Train_Accuracy: 0.00%\n\tVal_Loss: 2.894,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.782, Train_Accuracy: 0.00%\n\tVal_Loss: 2.837,  Val_Accuracy: 0.02%\nEpoch: 6\n\tTrain_Loss: 2.735, Train_Accuracy: 0.00%\n\tVal_Loss: 2.797,  Val_Accuracy: 0.05%\nEpoch: 7\n\tTrain_Loss: 2.698, Train_Accuracy: 0.00%\n\tVal_Loss: 2.741,  Val_Accuracy: 0.02%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▅█▅</td></tr><tr><td>Val_Loss</td><td>██▆▅▃▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁█▁█▁</td></tr><tr><td>training_loss</td><td>█▄▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.02441</td></tr><tr><td>Val_Loss</td><td>2.74133</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.69841</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">warm-sweep-19</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1ofys77n' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1ofys77n</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_073448-1ofys77n/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x359tq53 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_073952-x359tq53</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/x359tq53' target=\"_blank\">silver-sweep-20</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/x359tq53' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/x359tq53</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 64, num_layers=2, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 64, batch_first=True)\n    (fc): Linear(in_features=64, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.998, Train_Accuracy: 0.00%\n\tVal_Loss: 3.217,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.955, Train_Accuracy: 0.00%\n\tVal_Loss: 3.115,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.941, Train_Accuracy: 0.00%\n\tVal_Loss: 3.082,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.935, Train_Accuracy: 0.00%\n\tVal_Loss: 3.094,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.933, Train_Accuracy: 0.00%\n\tVal_Loss: 3.108,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.934, Train_Accuracy: 0.00%\n\tVal_Loss: 3.137,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.931, Train_Accuracy: 0.00%\n\tVal_Loss: 3.132,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▃▁▂▂▄▄</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▄▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.13184</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.93131</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silver-sweep-20</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/x359tq53' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/x359tq53</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_073952-x359tq53/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4gumauyv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_074421-4gumauyv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/4gumauyv' target=\"_blank\">fresh-sweep-21</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/4gumauyv' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/4gumauyv</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 1024, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=1024, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 55.365, Train_Accuracy: 0.00%\n\tVal_Loss: 44.881,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 50.499, Train_Accuracy: 0.00%\n\tVal_Loss: 52.492,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 51.907, Train_Accuracy: 0.00%\n\tVal_Loss: 54.862,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 51.634, Train_Accuracy: 0.00%\n\tVal_Loss: 56.787,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 51.413, Train_Accuracy: 0.00%\n\tVal_Loss: 52.221,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 51.046, Train_Accuracy: 0.00%\n\tVal_Loss: 44.002,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 50.840, Train_Accuracy: 0.00%\n\tVal_Loss: 49.216,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▆▇█▆▁▄</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▁▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>49.21648</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>50.84049</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fresh-sweep-21</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/4gumauyv' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/4gumauyv</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_074421-4gumauyv/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rnnc5kc5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_075253-rnnc5kc5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/rnnc5kc5' target=\"_blank\">skilled-sweep-22</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/rnnc5kc5' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/rnnc5kc5</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(256, 128, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(256, 768, batch_first=True)\n    (fc): Linear(in_features=768, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 1.570, Train_Accuracy: 5.31%\n\tVal_Loss: 1.405,  Val_Accuracy: 12.99%\nEpoch: 2\n\tTrain_Loss: 0.923, Train_Accuracy: 14.22%\n\tVal_Loss: 1.281,  Val_Accuracy: 19.53%\nEpoch: 3\n\tTrain_Loss: 0.761, Train_Accuracy: 18.40%\n\tVal_Loss: 1.266,  Val_Accuracy: 22.19%\nEpoch: 4\n\tTrain_Loss: 0.665, Train_Accuracy: 20.86%\n\tVal_Loss: 1.217,  Val_Accuracy: 27.54%\nEpoch: 5\n\tTrain_Loss: 0.607, Train_Accuracy: 22.15%\n\tVal_Loss: 1.211,  Val_Accuracy: 25.29%\nEpoch: 6\n\tTrain_Loss: 0.552, Train_Accuracy: 20.25%\n\tVal_Loss: 1.130,  Val_Accuracy: 29.59%\nEpoch: 7\n\tTrain_Loss: 0.511, Train_Accuracy: 20.91%\n\tVal_Loss: 1.147,  Val_Accuracy: 26.86%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▄▅▇▆█▇</td></tr><tr><td>Val_Loss</td><td>█▅▄▃▃▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇█▇▇</td></tr><tr><td>training_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>26.85547</td></tr><tr><td>Val_Loss</td><td>1.14699</td></tr><tr><td>train_accuracy</td><td>20.91016</td></tr><tr><td>training_loss</td><td>0.51052</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">skilled-sweep-22</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/rnnc5kc5' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/rnnc5kc5</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_075253-rnnc5kc5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5f9v61sa with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_075743-5f9v61sa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5f9v61sa' target=\"_blank\">woven-sweep-23</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5f9v61sa' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5f9v61sa</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(32, 512, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(32, 512, batch_first=True)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.825, Train_Accuracy: 0.00%\n\tVal_Loss: 2.823,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.458, Train_Accuracy: 0.00%\n\tVal_Loss: 2.550,  Val_Accuracy: 0.07%\nEpoch: 3\n\tTrain_Loss: 2.260, Train_Accuracy: 0.01%\n\tVal_Loss: 2.331,  Val_Accuracy: 0.15%\nEpoch: 4\n\tTrain_Loss: 2.105, Train_Accuracy: 0.05%\n\tVal_Loss: 2.226,  Val_Accuracy: 0.37%\nEpoch: 5\n\tTrain_Loss: 1.996, Train_Accuracy: 0.09%\n\tVal_Loss: 2.135,  Val_Accuracy: 0.85%\nEpoch: 6\n\tTrain_Loss: 1.890, Train_Accuracy: 0.16%\n\tVal_Loss: 2.024,  Val_Accuracy: 1.44%\nEpoch: 7\n\tTrain_Loss: 1.813, Train_Accuracy: 0.16%\n\tVal_Loss: 2.011,  Val_Accuracy: 2.32%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▂▄▅█</td></tr><tr><td>Val_Loss</td><td>█▆▄▃▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▃▅██</td></tr><tr><td>training_loss</td><td>█▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>2.31934</td></tr><tr><td>Val_Loss</td><td>2.01066</td></tr><tr><td>train_accuracy</td><td>0.16016</td></tr><tr><td>training_loss</td><td>1.8131</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">woven-sweep-23</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5f9v61sa' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/5f9v61sa</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_075743-5f9v61sa/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1eeiuddk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_080217-1eeiuddk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1eeiuddk' target=\"_blank\">copper-sweep-24</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1eeiuddk' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1eeiuddk</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 16, num_layers=2, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 16, batch_first=True)\n    (fc): Linear(in_features=16, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.001, Train_Accuracy: 0.00%\n\tVal_Loss: 3.039,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.841, Train_Accuracy: 0.00%\n\tVal_Loss: 2.880,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.721, Train_Accuracy: 0.00%\n\tVal_Loss: 2.767,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.645, Train_Accuracy: 0.00%\n\tVal_Loss: 2.646,  Val_Accuracy: 0.05%\nEpoch: 5\n\tTrain_Loss: 2.592, Train_Accuracy: 0.00%\n\tVal_Loss: 2.635,  Val_Accuracy: 0.10%\nEpoch: 6\n\tTrain_Loss: 2.549, Train_Accuracy: 0.00%\n\tVal_Loss: 2.622,  Val_Accuracy: 0.07%\nEpoch: 7\n\tTrain_Loss: 2.526, Train_Accuracy: 0.01%\n\tVal_Loss: 2.562,  Val_Accuracy: 0.07%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▅█▆▆</td></tr><tr><td>Val_Loss</td><td>█▆▄▂▂▂▁</td></tr><tr><td>train_accuracy</td><td>▃▁▁▃▆▆█</td></tr><tr><td>training_loss</td><td>█▆▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.07324</td></tr><tr><td>Val_Loss</td><td>2.56157</td></tr><tr><td>train_accuracy</td><td>0.00586</td></tr><tr><td>training_loss</td><td>2.52565</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">copper-sweep-24</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1eeiuddk' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/1eeiuddk</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_080217-1eeiuddk/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oqzkyvdp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_080645-oqzkyvdp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/oqzkyvdp' target=\"_blank\">graceful-sweep-25</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/oqzkyvdp' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/oqzkyvdp</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 128, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=128, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.930, Train_Accuracy: 0.00%\n\tVal_Loss: 2.851,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.843, Train_Accuracy: 0.00%\n\tVal_Loss: 2.820,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.843, Train_Accuracy: 0.00%\n\tVal_Loss: 2.817,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.826, Train_Accuracy: 0.00%\n\tVal_Loss: 2.823,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.840, Train_Accuracy: 0.00%\n\tVal_Loss: 2.891,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.832, Train_Accuracy: 0.00%\n\tVal_Loss: 2.813,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.821, Train_Accuracy: 0.00%\n\tVal_Loss: 2.770,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▄▄▄█▃▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>2.77022</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.82084</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">graceful-sweep-25</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/oqzkyvdp' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/oqzkyvdp</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_080645-oqzkyvdp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k6ca69jh with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_081125-k6ca69jh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/k6ca69jh' target=\"_blank\">rare-sweep-26</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/k6ca69jh' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/k6ca69jh</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(32, 16, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(32, 16, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=16, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.431, Train_Accuracy: 0.00%\n\tVal_Loss: 3.139,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.149, Train_Accuracy: 0.00%\n\tVal_Loss: 3.101,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 3.033, Train_Accuracy: 0.00%\n\tVal_Loss: 3.064,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.989, Train_Accuracy: 0.00%\n\tVal_Loss: 3.053,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.973, Train_Accuracy: 0.00%\n\tVal_Loss: 3.028,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.952, Train_Accuracy: 0.00%\n\tVal_Loss: 3.036,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 2.938, Train_Accuracy: 0.00%\n\tVal_Loss: 3.018,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▆▄▃▂▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▄▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.01775</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.93771</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rare-sweep-26</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/k6ca69jh' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/k6ca69jh</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_081125-k6ca69jh/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z5kmij4f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_081559-z5kmij4f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/z5kmij4f' target=\"_blank\">sunny-sweep-27</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/z5kmij4f' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/z5kmij4f</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(32, 256, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 32)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(32, 256, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=256, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.875, Train_Accuracy: 0.00%\n\tVal_Loss: 2.810,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.424, Train_Accuracy: 0.02%\n\tVal_Loss: 2.395,  Val_Accuracy: 0.22%\nEpoch: 3\n\tTrain_Loss: 2.162, Train_Accuracy: 0.02%\n\tVal_Loss: 2.235,  Val_Accuracy: 0.34%\nEpoch: 4\n\tTrain_Loss: 2.026, Train_Accuracy: 0.10%\n\tVal_Loss: 2.163,  Val_Accuracy: 0.81%\nEpoch: 5\n\tTrain_Loss: 1.920, Train_Accuracy: 0.13%\n\tVal_Loss: 2.036,  Val_Accuracy: 1.42%\nEpoch: 6\n\tTrain_Loss: 1.817, Train_Accuracy: 0.15%\n\tVal_Loss: 1.938,  Val_Accuracy: 1.81%\nEpoch: 7\n\tTrain_Loss: 1.727, Train_Accuracy: 0.13%\n\tVal_Loss: 1.926,  Val_Accuracy: 2.22%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▂▂▄▅▇█</td></tr><tr><td>Val_Loss</td><td>█▅▃▃▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▂▆▇█▇</td></tr><tr><td>training_loss</td><td>█▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>2.22168</td></tr><tr><td>Val_Loss</td><td>1.92575</td></tr><tr><td>train_accuracy</td><td>0.12695</td></tr><tr><td>training_loss</td><td>1.72715</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sunny-sweep-27</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/z5kmij4f' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/z5kmij4f</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_081559-z5kmij4f/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zbeydp7n with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_082054-zbeydp7n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zbeydp7n' target=\"_blank\">balmy-sweep-28</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zbeydp7n' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zbeydp7n</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 16, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 16, batch_first=True)\n    (fc): Linear(in_features=16, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.178, Train_Accuracy: 0.00%\n\tVal_Loss: 3.160,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.183, Train_Accuracy: 0.00%\n\tVal_Loss: 3.210,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 3.186, Train_Accuracy: 0.00%\n\tVal_Loss: 3.264,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 3.190, Train_Accuracy: 0.00%\n\tVal_Loss: 3.225,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 3.178, Train_Accuracy: 0.00%\n\tVal_Loss: 3.212,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 3.174, Train_Accuracy: 0.00%\n\tVal_Loss: 3.190,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 3.170, Train_Accuracy: 0.00%\n\tVal_Loss: 3.247,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄█▅▅▃▇</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>▄▅▆█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>3.24677</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>3.17049</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">balmy-sweep-28</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zbeydp7n' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/zbeydp7n</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_082054-zbeydp7n/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ti75t3pd with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_082527-ti75t3pd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ti75t3pd' target=\"_blank\">playful-sweep-29</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ti75t3pd' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ti75t3pd</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 32, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 32, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.005, Train_Accuracy: 0.00%\n\tVal_Loss: 2.964,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 2.852, Train_Accuracy: 0.00%\n\tVal_Loss: 2.948,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.792, Train_Accuracy: 0.00%\n\tVal_Loss: 2.855,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.742, Train_Accuracy: 0.00%\n\tVal_Loss: 2.815,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.701, Train_Accuracy: 0.00%\n\tVal_Loss: 2.726,  Val_Accuracy: 0.05%\nEpoch: 6\n\tTrain_Loss: 2.636, Train_Accuracy: 0.00%\n\tVal_Loss: 2.664,  Val_Accuracy: 0.02%\nEpoch: 7\n\tTrain_Loss: 2.595, Train_Accuracy: 0.00%\n\tVal_Loss: 2.606,  Val_Accuracy: 0.02%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.07160150414670581, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁█▅▅</td></tr><tr><td>Val_Loss</td><td>██▆▅▃▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▅▅█▁▁</td></tr><tr><td>training_loss</td><td>█▅▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.02441</td></tr><tr><td>Val_Loss</td><td>2.6059</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>2.59472</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">playful-sweep-29</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ti75t3pd' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ti75t3pd</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_082527-ti75t3pd/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cpy9anqr with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_083012-cpy9anqr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cpy9anqr' target=\"_blank\">fanciful-sweep-30</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cpy9anqr' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cpy9anqr</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 32, num_layers=2, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 32, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_34/2511518392.py\", line 61, in main\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n  File \"/tmp/ipykernel_34/2440559799.py\", line 11, in train\n    output = model(source, target)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/2483102920.py\", line 89, in forward\n    h_n = torch.cat([h_n, zero_h], dim=0)\nRuntimeError: Sizes of tensors must match except in dimension 0. Expected size 32 but got size 64 for tensor number 1 in the list.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fanciful-sweep-30</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cpy9anqr' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/cpy9anqr</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_083012-cpy9anqr/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run cpy9anqr errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/2511518392.py\", line 61, in main\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n  File \"/tmp/ipykernel_34/2440559799.py\", line 11, in train\n    output = model(source, target)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/2483102920.py\", line 89, in forward\n    h_n = torch.cat([h_n, zero_h], dim=0)\nRuntimeError: Sizes of tensors must match except in dimension 0. Expected size 32 but got size 64 for tensor number 1 in the list.\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run cpy9anqr errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/2511518392.py\", line 61, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/2440559799.py\", line 11, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(source, target)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/2483102920.py\", line 89, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     h_n = torch.cat([h_n, zero_h], dim=0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Sizes of tensors must match except in dimension 0. Expected size 32 but got size 64 for tensor number 1 in the list.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qu1936fe with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_083043-qu1936fe</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qu1936fe' target=\"_blank\">glamorous-sweep-31</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qu1936fe' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qu1936fe</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(16, 32, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=32, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.285, Train_Accuracy: 0.00%\n\tVal_Loss: 3.078,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.049, Train_Accuracy: 0.00%\n\tVal_Loss: 3.021,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 2.926, Train_Accuracy: 0.00%\n\tVal_Loss: 3.015,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 2.867, Train_Accuracy: 0.00%\n\tVal_Loss: 2.965,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 2.787, Train_Accuracy: 0.00%\n\tVal_Loss: 2.799,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 2.679, Train_Accuracy: 0.00%\n\tVal_Loss: 2.711,  Val_Accuracy: 0.05%\nEpoch: 7\n\tTrain_Loss: 2.603, Train_Accuracy: 0.00%\n\tVal_Loss: 2.642,  Val_Accuracy: 0.07%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▆█</td></tr><tr><td>Val_Loss</td><td>█▇▇▆▄▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▅▅▁██</td></tr><tr><td>training_loss</td><td>█▆▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.07324</td></tr><tr><td>Val_Loss</td><td>2.64182</td></tr><tr><td>train_accuracy</td><td>0.00391</td></tr><tr><td>training_loss</td><td>2.6032</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glamorous-sweep-31</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qu1936fe' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qu1936fe</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_083043-qu1936fe/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hmnvppqg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_083537-hmnvppqg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hmnvppqg' target=\"_blank\">summer-sweep-32</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hmnvppqg' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hmnvppqg</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 16)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(16, 1536, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=1536, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 3.105, Train_Accuracy: 0.00%\n\tVal_Loss: 3.045,  Val_Accuracy: 0.00%\nEpoch: 2\n\tTrain_Loss: 3.068, Train_Accuracy: 0.00%\n\tVal_Loss: 2.993,  Val_Accuracy: 0.00%\nEpoch: 3\n\tTrain_Loss: 3.065, Train_Accuracy: 0.00%\n\tVal_Loss: 2.991,  Val_Accuracy: 0.00%\nEpoch: 4\n\tTrain_Loss: 3.073, Train_Accuracy: 0.00%\n\tVal_Loss: 3.013,  Val_Accuracy: 0.00%\nEpoch: 5\n\tTrain_Loss: 3.071, Train_Accuracy: 0.00%\n\tVal_Loss: 3.060,  Val_Accuracy: 0.00%\nEpoch: 6\n\tTrain_Loss: 3.068, Train_Accuracy: 0.00%\n\tVal_Loss: 3.036,  Val_Accuracy: 0.00%\nEpoch: 7\n\tTrain_Loss: 3.076, Train_Accuracy: 0.00%\n\tVal_Loss: 2.995,  Val_Accuracy: 0.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded\\r'), FloatProgress(value=0.0722528329348165, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▁▁▃█▆▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▂▁▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>2.9948</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>training_loss</td><td>3.07595</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">summer-sweep-32</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hmnvppqg' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/hmnvppqg</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_083537-hmnvppqg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 480so5xl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_084958-480so5xl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/480so5xl' target=\"_blank\">jolly-sweep-33</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/480so5xl' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/480so5xl</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.211, Train_Accuracy: 1.25%\n\tVal_Loss: 1.555,  Val_Accuracy: 9.81%\nEpoch: 2\n\tTrain_Loss: 1.076, Train_Accuracy: 8.88%\n\tVal_Loss: 1.331,  Val_Accuracy: 17.50%\nEpoch: 3\n\tTrain_Loss: 0.823, Train_Accuracy: 14.23%\n\tVal_Loss: 1.236,  Val_Accuracy: 23.36%\nEpoch: 4\n\tTrain_Loss: 0.685, Train_Accuracy: 18.55%\n\tVal_Loss: 1.219,  Val_Accuracy: 25.59%\nEpoch: 5\n\tTrain_Loss: 0.606, Train_Accuracy: 20.46%\n\tVal_Loss: 1.153,  Val_Accuracy: 23.19%\nEpoch: 6\n\tTrain_Loss: 0.537, Train_Accuracy: 22.59%\n\tVal_Loss: 1.170,  Val_Accuracy: 30.08%\nEpoch: 7\n\tTrain_Loss: 0.490, Train_Accuracy: 21.93%\n\tVal_Loss: 1.107,  Val_Accuracy: 33.91%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▃▅▆▅▇█</td></tr><tr><td>Val_Loss</td><td>█▅▃▃▂▂▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▇▇██</td></tr><tr><td>training_loss</td><td>█▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>33.91113</td></tr><tr><td>Val_Loss</td><td>1.10666</td></tr><tr><td>train_accuracy</td><td>21.92773</td></tr><tr><td>training_loss</td><td>0.49028</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jolly-sweep-33</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/480so5xl' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/480so5xl</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_084958-480so5xl/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wd6w5wfr with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_085532-wd6w5wfr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wd6w5wfr' target=\"_blank\">robust-sweep-34</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wd6w5wfr' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wd6w5wfr</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=256, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.708, Train_Accuracy: 0.03%\n\tVal_Loss: 2.173,  Val_Accuracy: 0.51%\nEpoch: 2\n\tTrain_Loss: 1.565, Train_Accuracy: 2.94%\n\tVal_Loss: 1.439,  Val_Accuracy: 11.50%\nEpoch: 3\n\tTrain_Loss: 1.082, Train_Accuracy: 7.88%\n\tVal_Loss: 1.297,  Val_Accuracy: 15.36%\nEpoch: 4\n\tTrain_Loss: 0.894, Train_Accuracy: 10.95%\n\tVal_Loss: 1.248,  Val_Accuracy: 20.31%\nEpoch: 5\n\tTrain_Loss: 0.781, Train_Accuracy: 13.05%\n\tVal_Loss: 1.171,  Val_Accuracy: 27.49%\nEpoch: 6\n\tTrain_Loss: 0.702, Train_Accuracy: 14.94%\n\tVal_Loss: 1.149,  Val_Accuracy: 27.66%\nEpoch: 7\n\tTrain_Loss: 0.648, Train_Accuracy: 17.24%\n\tVal_Loss: 1.138,  Val_Accuracy: 26.37%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▄▅▆███</td></tr><tr><td>Val_Loss</td><td>█▃▂▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▄▅▆▇█</td></tr><tr><td>training_loss</td><td>█▄▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>26.36719</td></tr><tr><td>Val_Loss</td><td>1.1383</td></tr><tr><td>train_accuracy</td><td>17.23828</td></tr><tr><td>training_loss</td><td>0.64753</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">robust-sweep-34</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wd6w5wfr' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/wd6w5wfr</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_085532-wd6w5wfr/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qtzmht1w with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_090046-qtzmht1w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qtzmht1w' target=\"_blank\">decent-sweep-35</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qtzmht1w' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qtzmht1w</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 2.156, Train_Accuracy: 1.85%\n\tVal_Loss: 1.551,  Val_Accuracy: 10.50%\nEpoch: 2\n\tTrain_Loss: 1.064, Train_Accuracy: 10.86%\n\tVal_Loss: 1.299,  Val_Accuracy: 20.85%\nEpoch: 3\n\tTrain_Loss: 0.829, Train_Accuracy: 16.97%\n\tVal_Loss: 1.254,  Val_Accuracy: 22.88%\nEpoch: 4\n\tTrain_Loss: 0.704, Train_Accuracy: 16.88%\n\tVal_Loss: 1.164,  Val_Accuracy: 27.56%\nEpoch: 5\n\tTrain_Loss: 0.622, Train_Accuracy: 17.04%\n\tVal_Loss: 1.188,  Val_Accuracy: 19.41%\nEpoch: 6\n\tTrain_Loss: 0.565, Train_Accuracy: 19.95%\n\tVal_Loss: 1.171,  Val_Accuracy: 29.59%\nEpoch: 7\n\tTrain_Loss: 0.514, Train_Accuracy: 22.95%\n\tVal_Loss: 1.154,  Val_Accuracy: 29.57%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>▁▅▆▇▄██</td></tr><tr><td>Val_Loss</td><td>█▄▃▁▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▆▆▇█</td></tr><tr><td>training_loss</td><td>█▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Val_Accuracy</td><td>29.56543</td></tr><tr><td>Val_Loss</td><td>1.15352</td></tr><tr><td>train_accuracy</td><td>22.94531</td></tr><tr><td>training_loss</td><td>0.51416</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">decent-sweep-35</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qtzmht1w' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/qtzmht1w</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_090046-qtzmht1w/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b90zfijx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_090623-b90zfijx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/b90zfijx' target=\"_blank\">sage-sweep-36</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/u9usg77k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/b90zfijx' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/b90zfijx</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 512)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(512, 1536, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=1536, out_features=100, bias=True)\n  )\n)\nEpoch: 1\n\tTrain_Loss: 1.487, Train_Accuracy: 5.37%\n\tVal_Loss: 1.461,  Val_Accuracy: 15.70%\nEpoch: 2\n\tTrain_Loss: 0.849, Train_Accuracy: 12.16%\n\tVal_Loss: 1.278,  Val_Accuracy: 20.92%\nEpoch: 3\n\tTrain_Loss: 0.682, Train_Accuracy: 16.16%\n\tVal_Loss: 1.203,  Val_Accuracy: 26.29%\nEpoch: 4\n\tTrain_Loss: 0.584, Train_Accuracy: 18.63%\n\tVal_Loss: 1.181,  Val_Accuracy: 27.83%\nEpoch: 5\n\tTrain_Loss: 0.524, Train_Accuracy: 15.05%\n\tVal_Loss: 1.145,  Val_Accuracy: 24.68%\nEpoch: 6\n\tTrain_Loss: 0.471, Train_Accuracy: 21.66%\n\tVal_Loss: 1.152,  Val_Accuracy: 30.52%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **For training and testing model on the training and test dataset wandb setup**","metadata":{}},{"cell_type":"code","source":"# -embed_size-64-layers_enc-3-layers_dec-3-hid_size-512-cell_type-lstm-bidirectional-True-dropout-0.2\n\nsweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep test 2',\n    'metric': {\n        'name': 'Test_Accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'input_embed_size': {\n            'values': [64]\n        },\n        'num_enc_layers':{\n            'values': [3]\n        },\n        'num_dec_layers':{\n            'values': [3]\n        },\n        'hid_layer_size': {\n            'values': [512]\n        },\n        'cell_type': {\n            'values': ['lstm']\n        },\n        'bidirectional':{\n            'values': [True]\n        },\n        'dropout': {\n            'values': [0.2]\n        },\n        'new_learning_rate':{\n            'values': [0.001]\n        }\n#       'beam search in decoder with different beam sizes': \n    }\n}\n\nsweep_id = wandb.sweep(sweep = sweep_config, project=\"Deep_Learning_A3\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:36:16.255195Z","iopub.execute_input":"2024-05-17T12:36:16.255637Z","iopub.status.idle":"2024-05-17T12:36:16.523635Z","shell.execute_reply.started":"2024-05-17T12:36:16.255604Z","shell.execute_reply":"2024-05-17T12:36:16.522596Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Create sweep with ID: 34ygj7rs\nSweep URL: https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/34ygj7rs\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\ndef main():\n    # Initialize a new wandb run\n    with wandb.init() as run:\n        # Construct run name from configuration\n        run_name = \"-embed_size-\"+str(wandb.config.input_embed_size)+\"-layers_enc-\"+str(wandb.config.num_enc_layers)+\"-layers_dec-\"+str(wandb.config.num_dec_layers)+\"-hid_size-\"+str(wandb.config.hid_layer_size)+\"-cell_type-\"+wandb.config.cell_type+\"-bidirectional-\"+str(wandb.config.bidirectional)+\"-dropout-\"+str(wandb.config.dropout)+\"-lr-\"+str(wandb.config.new_learning_rate)\n        wandb.run.name = run_name\n\n        # Constants defining the dimensions of the input and output character sets\n        INPUT_DIM = 100  # size of the Latin character set\n        OUTPUT_DIM = 100  # size of the Bangla character set\n\n        # Constants defining the dimensions of the embeddings for encoder and decoder\n        ENC_EMB_DIM = wandb.config.input_embed_size  # Encoder embedding dimension\n        DEC_EMB_DIM = wandb.config.input_embed_size  # Decoder embedding dimension\n\n        # Constants defining the dimension of the hidden layers for encoder and decoder\n        HID_DIM = wandb.config.hid_layer_size  # Hidden dimension size\n\n        # Constants defining the number of layers for encoder and decoder\n        ENC_LAYERS = wandb.config.num_enc_layers  # Number of layers in the encoder\n        DEC_LAYERS = wandb.config.num_dec_layers  # Number of layers in the decoder\n        \n\n        # Constants defining the type of RNN cell to use for encoder and decoder\n        ENC_RNN_CELL = wandb.config.cell_type  # RNN cell type for the encoder\n        DEC_RNN_CELL = wandb.config.cell_type  # RNN cell type for the decoder\n\n        # Instantiate the encoder with specified configurations\n        encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_LAYERS, ENC_RNN_CELL, dropout = wandb.config.dropout, bidirectional = wandb.config.bidirectional)\n        # Instantiate the decoder with specified configurations\n        decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_LAYERS, encoder.num_layers, DEC_RNN_CELL, dropout = wandb.config.dropout, bidirectional = wandb.config.bidirectional)\n\n        # Determine the computing device (CUDA if available, otherwise CPU)\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        # Print the device will be used\n        print(f\"Using device: {device}\")\n\n        # Instantiate the Seq_to_Seq model and move it to the chosen computing device\n        model = Seq_to_Seq(encoder, decoder).to(device)\n        print(model)\n        \n        \n        # Setting the number of epochs the training process should run\n        NUM_EPOCHS = 20\n        # Set the maximum norm of the gradients to 1 to prevent exploding gradients\n        CLIP = 1\n        # Initialize the optimizer, Adam\n        optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.new_learning_rate)  # Set the learning rate to 0.001\n\n\n        # Padding token index should be ignored in loss calculation\n        ignore_index = bangla_token_to_index['<pad>']\n        # Define the loss function with 'ignore_index' to avoid affecting loss calculation with padding tokens\n        criterion = nn.CrossEntropyLoss(ignore_index=ignore_index).to(device)\n\n        # Start the training process for the defined number of epochs\n        for epoch in range(NUM_EPOCHS):\n            # Doing training on the train dataset and return average loss and accuracy\n            train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n            # Evaluating the model on the validation dataset and return average loss and accuracy\n            val_loss, val_accuracy = evaluate(model, test_loader, criterion, device, ignore_index)\n\n            # Print the loss and accuracy for each epoch\n            print(f'Epoch: {epoch+1}')\n            print(f'\\tTrain_Loss: {train_loss:.3f}, Train_Accuracy: {train_accuracy*100:.2f}%')\n            print(f'\\tTest_Loss: {val_loss:.3f},  Test_Accuracy: {val_accuracy*100:.2f}%')\n            wandb.log({\"train_accuracy\": train_accuracy * 100, \"training_loss\": train_loss})\n            wandb.log({\"Test_Accuracy\": val_accuracy * 100, \"Test_Loss\": val_loss})\n\n\nwandb.agent(sweep_id, function=main, count=1)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:36:21.544172Z","iopub.execute_input":"2024-05-17T12:36:21.544976Z","iopub.status.idle":"2024-05-17T12:36:45.010803Z","shell.execute_reply.started":"2024-05-17T12:36:21.544942Z","shell.execute_reply":"2024-05-17T12:36:45.009804Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ldnzzju5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnew_learning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_123623-ldnzzju5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ldnzzju5' target=\"_blank\">zesty-sweep-1</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/34ygj7rs' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/34ygj7rs</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/34ygj7rs' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/sweeps/34ygj7rs</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ldnzzju5' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ldnzzju5</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nSeq_to_Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(100, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(64, 1536, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=1536, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_34/970870673.py\", line 61, in main\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n  File \"/tmp/ipykernel_34/4219852660.py\", line 17, in train\n    output = model(source, target)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/594173864.py\", line 23, in forward\n    c_n = torch.cat([c_n[i:i+1] for i in range(0, c_n.shape[0], 2)] + [c_n[i:i+1] for i in range(1, c_n.shape[0], 2)], dim=2)\nAttributeError: 'tuple' object has no attribute 'shape'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">zesty-sweep-1</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ldnzzju5' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3/runs/ldnzzju5</a><br/> View project at: <a href='https://wandb.ai/parthasakhapaul/Deep_Learning_A3' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_Learning_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_123623-ldnzzju5/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ldnzzju5 errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/970870673.py\", line 61, in main\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n  File \"/tmp/ipykernel_34/4219852660.py\", line 17, in train\n    output = model(source, target)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/594173864.py\", line 23, in forward\n    c_n = torch.cat([c_n[i:i+1] for i in range(0, c_n.shape[0], 2)] + [c_n[i:i+1] for i in range(1, c_n.shape[0], 2)], dim=2)\nAttributeError: 'tuple' object has no attribute 'shape'\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ldnzzju5 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/970870673.py\", line 61, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, device, ignore_index)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/4219852660.py\", line 17, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(source, target)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/594173864.py\", line 23, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     c_n = torch.cat([c_n[i:i+1] for i in range(0, c_n.shape[0], 2)] + [c_n[i:i+1] for i in range(1, c_n.shape[0], 2)], dim=2)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AttributeError: 'tuple' object has no attribute 'shape'\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}